{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e819a3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html MSUFeb10.do.txt --no_mako -->\n",
    "<!-- dom:TITLE: Artificial Intelligence and Machine Learning in Nuclear Physics -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a052a15",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Artificial Intelligence and Machine Learning in Nuclear Physics\n",
    "**Morten Hjorth-Jensen, Dean Lee and Witek Nazarewicz**, Department of Physics and Astronomy and FRIB/NSCL Laboratory, Michigan State University\n",
    "\n",
    "Date: **Research Discussion, FRIB, Michigan State University, February 10, 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c519b6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What is this talk about?\n",
    "The main emphasis is to give you a short and pedestrian introduction to the whys and hows we can use Machine Learning methods\n",
    "to solve quantum mechanical many-body problems and how we can use such techniques in analysis of  experiments. And why this could (or should) be of interest.\n",
    "\n",
    "These slides are at <https://mhjensenseminars.github.io/MachineLearningTalk/doc/pub/>.\n",
    "\n",
    "**See also Artificial Intelligence and Machine Learning in Nuclear Physics**, Amber Boehnlein et al., [arXiv:2112.02309](https://arxiv.org/abs/2112.02309) and Reviews Modern of Physics, submitted.  MSU co-authors are Deal Lee, Witek Nazarewicz, Peter Ostroumov, and MHJ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bedf2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## A simple perspective on the interface between ML and Physics\n",
    "\n",
    "<!-- dom:FIGURE: [figures/mlimage.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/mlimage.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b8b94e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## ML in Nuclear  Physics\n",
    "\n",
    "<!-- dom:FIGURE: [figures/ML-NP.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/ML-NP.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe8991",
   "metadata": {
    "editable": true
   },
   "source": [
    "## ML in Materials Science and nanotechnologies, predicting candidates for quantum technologies (add figure)\n",
    "\n",
    "<!-- dom:FIGURE: [figures/fig2.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/fig2.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c2491",
   "metadata": {
    "editable": true
   },
   "source": [
    "## AI/ML and some statements you may hear more and more\n",
    "\n",
    "1. Fei-Fei Li on ImageNet: **map out the entire world of objects** ([The data that transformed AI research](https://cacm.acm.org/news/219702-the-data-that-transformed-ai-research-and-possibly-the-world/fulltext))\n",
    "\n",
    "2. Russell and Norvig in their popular textbook: **relevant to any intellectual task; it is truly a universal field** ([Artificial Intelligence, A modern approach](http://aima.cs.berkeley.edu/))\n",
    "\n",
    "3. Woody Bledsoe puts it more bluntly: **in the long run, AI is the only science** (quoted in McCorduck, [Machines who think](https://www.pamelamccorduck.com/machines-who-think))\n",
    "\n",
    "If you wish to have a critical read on AI/ML from a societal point of view, see [Kate Crawford's recent text Atlas of AI](https://www.katecrawford.net/)\n",
    "\n",
    "**Here: with AI/ML we intend a collection of machine learning methods with an emphasis on statistical learning and data analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9178332",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Scientific Machine Learning\n",
    "\n",
    "An important and emerging field is what has been dubbed as scientific ML, see the article by Deiana et al [Applications and Techniques for Fast Machine Learning in Science, arXiv:2110.13041](https://arxiv.org/abs/2110.13041)\n",
    "\n",
    "The authors discuss applications and techniques for fast machine\n",
    "learning (ML) in science - the concept of integrating power ML\n",
    "methods into the real-time experimental data processing loop to\n",
    "accelerate scientific discovery. The report covers three main areas\n",
    "\n",
    "1. applications for fast ML across a number of scientific domains;\n",
    "\n",
    "2. techniques for training and implementing performant and resource-efficient ML algorithms;\n",
    "\n",
    "3. and computing architectures, platforms, and technologies for deploying these algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd0034",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Machine learning & low-energy nuclear theory: Why?\n",
    "\n",
    "1. ML tools can help us to speed up the scientific process cycle and hence facilitate discoveries\n",
    "\n",
    "2. Enabling fast emulation for big simulations\n",
    "\n",
    "3. Revealing the information content of measured observables w.r.t. theory\n",
    "\n",
    "4. Identifying crucial experimental data for better constraining theory\n",
    "\n",
    "5. Providing meaningful input to applications and planned measurements\n",
    "\n",
    "6. ML tools can help us to reveal the structure of our models\n",
    "\n",
    "7. Parameter estimation with heterogeneous/multi-scale datasets\n",
    "\n",
    "8. Model reduction\n",
    "\n",
    "9. ML tools can help us to provide predictive capability\n",
    "\n",
    "10. Theoretical results often involve ultraviolet  and infrared extrapolations due to Hilbert-space truncations \n",
    "\n",
    "11. Uncertainty quantification essential\n",
    "\n",
    "12. Theoretical models are often applied to entirely new nuclear systems and conditions that are not accessible to experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534171fa",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The plethora  of machine learning algorithms/methods\n",
    "\n",
    "1. Deep learning: Neural Networks (NN), Convolutional NN, Recurrent NN, Boltzmann machines, autoencoders and variational autoencoders  and generative adversarial networks \n",
    "\n",
    "2. Bayesian statistics and Bayesian Machine Learning, Bayesian experimental design, Bayesian Regression models, Bayesian neural networks, Gaussian processes and much more\n",
    "\n",
    "3. Dimensionality reduction (Principal component analysis), Clustering Methods and more\n",
    "\n",
    "4. Ensemble Methods, Random forests, bagging and voting methods, gradient boosting approaches \n",
    "\n",
    "5. Linear and logistic regression, Kernel methods, support vector machines and more\n",
    "\n",
    "6. Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76883167",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on Machine Learning methods and applications in nuclear physics\n",
    "\n",
    "**Machine  learning  for  data  mining:** Oftentimes,  it  is necessary to be able to accurately calculate observables that have not been measured, to supplement the existing databases.\n",
    "**Nuclear  density  functional   theory:** Energy density functional calibration   involving Bayesian optimization  and NN  ML. A promising avenue for ML applications is the emulation of DFT results.\n",
    "**Nuclear properties with ML:** Improving predictive power of nuclear models by emulating model residuals.\n",
    "**Effective field theory and A-body systems:** Truncation errors and low-energy coupling constant calibration, nucleon-nucleon scattering calculations, variational calculations with ANN for light nuclei, NN extrapolation of nuclear structure observables\n",
    "**Nuclear  shell  model  UQ:** ML methods  have  been  used  to  provide  UQ  of  configuration  interaction  calculations.\n",
    "**Low-energy nuclear reactions UQ:** Bayesian optimization studies of the nucleon-nucleus optical potential, R-matrix analyses,  and  statistical spatial networks to study patterns in nuclear reaction networks.\n",
    "**Neutron star properties and nuclear matter equation of state:** constraining the equation of state by properties on neutron stars and selected properties of finite nuclei\n",
    "**Experimental design:** Bayesian ML provides a framework  to  maximize  the  success  of  on  experiment  based on  the  best  information  available  on existing  data, experimental conditions, and theoretical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edafa6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Machine Learning and Physics\n",
    "Machine learning  is an extremely rich field, in spite of its young age. The\n",
    "increases we have seen during the last three decades in computational\n",
    "capabilities have been followed by developments of methods and\n",
    "techniques for analyzing and handling large date sets, relying heavily\n",
    "on statistics, computer science and mathematics.  The field is rather\n",
    "new and developing rapidly. \n",
    "\n",
    "Popular software packages written in Python for ML are\n",
    "\n",
    "* [Scikit-learn](http://scikit-learn.org/stable/), \n",
    "\n",
    "* [Tensorflow](https://www.tensorflow.org/),\n",
    "\n",
    "* [PyTorch](http://pytorch.org/)\n",
    "\n",
    "* [Keras](https://keras.io/),\n",
    "\n",
    "and more. These are all freely available at their respective GitHub sites. They \n",
    "encompass communities of developers in the thousands or more. And the number\n",
    "of code developers and contributors keeps increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f139d2b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Lots of room for creativity\n",
    "Not all the\n",
    "algorithms and methods can be given a rigorous mathematical\n",
    "justification, opening up thereby for experimenting\n",
    "and trial and error and thereby exciting new developments.\n",
    "\n",
    "A solid command of linear algebra, multivariate theory, \n",
    "probability theory, statistical data analysis, optimization algorithms, \n",
    "understanding errors and Monte Carlo methods is important in order to understand many of the \n",
    "various algorithms and methods.\n",
    "\n",
    "**Job market, a personal statement**: [A familiarity with ML is almost becoming a prerequisite for many of the most exciting employment opportunities](https://www.analyticsindiamag.com/top-countries-hiring-most-number-of-artificial-intelligence-machine-learning-experts/). And add quantum computing and there you are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b896c0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Types of Machine Learning\n",
    "\n",
    "The approaches to machine learning are many, but are often split into two main categories. \n",
    "In *supervised learning* we know the answer to a problem,\n",
    "and let the computer deduce the logic behind it. On the other hand, *unsupervised learning*\n",
    "is a method for finding patterns and relationship in data sets without any prior knowledge of the system.\n",
    "Some authours also operate with a third category, namely *reinforcement learning*. This is a paradigm \n",
    "of learning inspired by behavioural psychology, where learning is achieved by trial-and-error, \n",
    "solely from rewards and punishment.\n",
    "\n",
    "Another way to categorize machine learning tasks is to consider the desired output of a system.\n",
    "Some of the most common tasks are:\n",
    "\n",
    "  * Classification: Outputs are divided into two or more classes. The goal is to   produce a model that assigns inputs into one of these classes. An example is to identify  digits based on pictures of hand-written ones. Classification is typically supervised learning.\n",
    "\n",
    "  * Regression: Finding a functional relationship between an input data set and a reference data set.   The goal is to construct a function that maps input data to continuous output values.\n",
    "\n",
    "  * Clustering: Data are divided into groups with certain common traits, without knowing the different groups beforehand.  It is thus a form of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71100b61",
   "metadata": {
    "editable": true
   },
   "source": [
    "## ML in Nuclear Physics, Examples\n",
    "\n",
    "The large amount of degrees of freedom pertain to both theory and experiment in nuclear physics. With increasingly complicated experiments that produce large amounts data, automated classification of events becomes increasingly important. Here, deep learning methods offer a plethora of interesting research avenues. \n",
    "\n",
    "* Reconstruction of particle trajectories or classification of events are typical examples where ML methods are being used. However, since these data can often be extremely noisy, the precision necessary for discovery in physics requires algorithmic improvements. Research along such directions, interfacing nuclear physics with AI/ML is expected to play a significant role in physics discoveries related to new facilities.  The treatment of corrupted data in imaging and image processing is also a relevant topic. \n",
    "\n",
    "* Design of detectors represents an important area of applications for ML/AI methods in nuclear physics.\n",
    "\n",
    "* Many of the above classification problems have also have direct application in theoretical nuclear physics (including Lattice QCD calculations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372395f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More examples\n",
    "\n",
    "* An important application of AI/ML methods is to improve the estimation of bias or uncertainty due to the introduction of or lack of physical constraints in various theoretical models.\n",
    "\n",
    "* In theory, we expect to use AI/ML algorithms and methods to improve our knowledged about  correlations of physical model parameters in data for quantum many-body systems. Deep learning methods like Boltzmann machines and various types of Recurrent Neural networks show great promise in circumventing the exploding dimensionalities encountered in quantum mechanical many-body studies. \n",
    "\n",
    "* Merging a frequentist approach (the standard path in ML theory) with a Bayesian approach, has the potential to infer better probabilitity distributions and error estimates. As an example, methods for fast Monte-Carlo- based Bayesian computation of nuclear density functionals show great promise in providing a better understanding \n",
    "\n",
    "* Machine Learning and Quantum Computing is a very interesting avenue to explore. See for example talk of [Sofia Vallecorsa](https://www.youtube.com/watch?v=7WPKv1Q57os&list=PLUPPQ1TVXK7uHwCTccWMBud-zLyvAf8A2&index=5&ab_channel=ECTstar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea2e5d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Selected References\n",
    "* [Mehta et al.](https://arxiv.org/abs/1803.08823) and [Physics Reports (2019)](https://www.sciencedirect.com/science/article/pii/S0370157319300766?via%3Dihub).\n",
    "\n",
    "* [Machine Learning and the Physical Sciences by Carleo et al](https://link.aps.org/doi/10.1103/RevModPhys.91.045002)\n",
    "\n",
    "* [Ab initio solution of the many-electron Schr√∂dinger equation with deep neural networks by Pfau et al.](https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.033429).\n",
    "\n",
    "* [Machine Learning and the Deuteron by Kebble and Rios](https://www.sciencedirect.com/science/article/pii/S0370269320305463?via%3Dihub)\n",
    "\n",
    "* [Variational Monte Carlo calculations of $A\\le 4$ nuclei with an artificial neural-network correlator ansatz by Adams et al.](https://arxiv.org/abs/2007.14282)\n",
    "\n",
    "* [Unsupervised Learning for Identifying Events in Active Target Experiments by Solli et al.](https://arxiv.org/abs/2006.05422)\n",
    "\n",
    "* [Report from the A.I. For Nuclear Physics  Workshop by Bedaque et al.](https://arxiv.org/abs/2006.05422)\n",
    "\n",
    "* [Applications and Techniques for Fast Machine Learning in Science](https://arxiv.org/abs/2110.13041)\n",
    "\n",
    "* [Particle Data Group summary on ML methods](https://pdg.lbl.gov/2021/reviews/rpp2021-rev-machine-learning.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cbefd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What are the basic ingredients?\n",
    "Almost every problem in ML and data science starts with the same ingredients:\n",
    "* The dataset $\\mathbf{x}$ (could be some observable quantity of the system we are studying)\n",
    "\n",
    "* A model which is a function of a set of parameters $\\mathbf{\\alpha}$ that relates to the dataset, say a likelihood  function $p(\\mathbf{x}\\vert \\mathbf{\\alpha})$ or just a simple model $f(\\mathbf{\\alpha})$\n",
    "\n",
    "* A so-called **loss/cost/risk** function $\\mathcal{C} (\\mathbf{x}, f(\\mathbf{\\alpha}))$ which allows us to decide how well our model represents the dataset. \n",
    "\n",
    "We seek to minimize the function $\\mathcal{C} (\\mathbf{x}, f(\\mathbf{\\alpha}))$ by finding the parameter values which minimize $\\mathcal{C}$. This leads to  various minimization algorithms. It may surprise many, but at the heart of all machine learning algortihms there is an optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa681e43",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Neural network types\n",
    "An artificial neural network (NN), is a computational model that consists of layers of connected neurons, or *nodes*. \n",
    "It is supposed to mimic a biological nervous system by letting each neuron interact with other neurons\n",
    "by sending signals in the form of mathematical functions between layers. \n",
    "A wide variety of different NNs have\n",
    "been developed, but most of them consist of an input layer, an output layer and eventual layers in-between, called\n",
    "*hidden layers*. All layers can contain an arbitrary number of nodes, and each connection between two nodes\n",
    "is associated with a weight variable. \n",
    "\n",
    "<!-- dom:FIGURE: [figures/dnn.png, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/dnn.png\" width=\"500\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f98c9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## [Nuclear Physics Experiments Argon-46, Solli et al.](https://www.sciencedirect.com/science/article/abs/pii/S0168900221004460?via%3Dihub)\n",
    "\n",
    "Two- and three-dimensional representations of two events from the\n",
    "Argon-46 experiment. Each row is one event in two projections,\n",
    "where the color intensity of each point indicates higher charge values\n",
    "recorded by the detector. The bottom row illustrates a carbon event with\n",
    "a large fraction of noise, while the top row shows a proton event\n",
    "almost free of noise. See [Unsupervised Learning for Identifying Events in Active Target Experiments by Solli et al.](https://arxiv.org/abs/2008.02757) for more detials.\n",
    "\n",
    "<!-- dom:FIGURE: [figures/examples_raw.png, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/examples_raw.png\" width=\"500\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee27325",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why Machine Learning?\n",
    "\n",
    "The traditional Monte Carlo event selection process does not have a\n",
    "well-defined method to quantify the effectiveness of the event\n",
    "selection.\n",
    "\n",
    "In addition, the selection task normally produces  a binary result only, either\n",
    "a **good** or **bad** fit to the event of interest. A **bad**\n",
    "fit is then assumed to be a different event type, and is removed from\n",
    "the analysis. \n",
    "\n",
    "In a broader perspective, an\n",
    "unsupervised classification algorithm would offer the possibility to\n",
    "*discover* rare events which may not be expected or are\n",
    "overlooked. These events would likely be filtered out using the\n",
    "traditional methods. From a practical point of view, compared to\n",
    "supervised learning, it also avoids the necessary labeling task of the\n",
    "learning set events, which is error prone and time consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b2585",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why Machine Learning for Experimental Analysis?\n",
    "\n",
    "The $\\chi^2$ approach used in the traditional analysis performed on\n",
    "the Argon-46 data is extremely expensive from a computational stand\n",
    "because it involves the simulation of thousands of tracks for each\n",
    "recorded event.\n",
    "\n",
    "These events are in turn simulated for each iteration of the Monte\n",
    "Carlo fitting sequence.  Even though the reaction of interest in the\n",
    "above experiment had the largest cross section (elastic scattering),\n",
    "the time spent on Monte Carlo fitting of *all* of the events\n",
    "produced in the experiment was the largest computational bottleneck in\n",
    "the analysis. In the case of an experiment where the reaction of\n",
    "interest would represent less than a few percent of the total cross\n",
    "section, this procedure would become highly inefficient and\n",
    "prohibitive. Adding to this the large amount of data produced in this\n",
    "experiment (with even larger data sets expected in future\n",
    "experiments), the analysis simply begs for more efficient analysis\n",
    "tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8483fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More arguments\n",
    "\n",
    "The computationally expensive fitting procedure\n",
    "would be applied to every event, instead of the few percent of the\n",
    "events that are of interest for the analysis.  An unsupervised ML\n",
    "algorithm able to separate the data without *a priori* knowledge\n",
    "of the different types of events increases the efficiency of the\n",
    "analysis tremendously, and allows the downstream analysis to\n",
    "concentrate on the fitting efforts only on events of interest. In\n",
    "addition, the clustering allows for more exploration of the data,\n",
    "potentially enabling new discovery of unexpected reaction types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffeb123",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum Monte Carlo Motivation\n",
    "Given a hamiltonian $H$ and a trial wave function $\\Psi_T$, the variational principle states that the expectation value of $\\langle H \\rangle$, defined through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d760aa",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle E \\rangle =\n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})H(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01f4b9",
   "metadata": {
    "editable": true
   },
   "source": [
    "is an upper bound to the ground state energy $E_0$ of the hamiltonian $H$, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91808743",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_0 \\le \\langle E \\rangle.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613e8f2",
   "metadata": {
    "editable": true
   },
   "source": [
    "In general, the integrals involved in the calculation of various  expectation values  are multi-dimensional ones. Traditional integration methods such as the Gauss-Legendre will not be adequate for say the  computation of the energy of a many-body system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f0280",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Running the codes\n",
    "You can find the codes, in c++,  for the simple two-electron case at the Github repository <https://github.com/mhjensenseminars/MachineLearningTalk/tree/master/doc/Programs/MLcpp/src> or in python at <http://compphysics.github.io/ComputationalPhysics2/doc/LectureNotes/_build/html/boltzmannmachines.html> \n",
    "\n",
    "The trial wave function are based on the product of a Slater determinant with either only Hermitian polynomials or Gaussian orbitals, with and without a Pade-Jastrow factor (PJ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b338cd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Deep Learning Neural Networks\n",
    "\n",
    "[Machine Learning and the Deuteron by Kebble and Rios](https://www.sciencedirect.com/science/article/pii/S0370269320305463?via%3Dihub) and \n",
    "[Variational Monte Carlo calculations of $A\\le 4$ nuclei with an artificial neural-network correlator ansatz by Adams et al.](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.127.022502)\n",
    "\n",
    "**Adams et al**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4cef3a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "H_{LO} =-\\sum_i \\frac{{\\vec{\\nabla}_i^2}}{2m_N}\n",
    "+\\sum_{i<j} {\\left(C_1  + C_2\\, \\vec{\\sigma_i}\\cdot\\vec{\\sigma_j}\\right)\n",
    "e^{-r_{ij}^2\\Lambda^2 / 4 }}\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174eec9",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "+D_0 \\sum_{i<j<k} \\sum_{\\text{cyc}}\n",
    "{e^{-\\left(r_{ik}^2+r_{ij}^2\\right)\\Lambda^2/4}}\\,,\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd9510",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $m_N$ is the mass of the nucleon, $\\vec{\\sigma_i}$ is the Pauli\n",
    "matrix acting on nucleon $i$, and $\\sum_{\\text{cyc}}$ stands for the\n",
    "cyclic permutation of $i$, $j$, and $k$. The low-energy constants\n",
    "$C_1$ and $C_2$ are fit to the deuteron binding energy and to the\n",
    "neutron-neutron scattering length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187a9c9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Replacing the Jastrow factor with Neural Networks\n",
    "\n",
    "An appealing feature of the ANN ansatz is that it is more general than the more conventional product of two-\n",
    "and three-body spin-independent Jastrow functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0bee9",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "|\\Psi_V^J \\rangle = \\prod_{i<j<k} \\Big( 1-\\sum_{\\text{cyc}} u(r_{ij}) u(r_{jk})\\Big) \\prod_{i<j} f(r_{ij}) | \\Phi\\rangle\\,,\n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e52b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is commonly used for nuclear Hamiltonians that do not contain tensor and spin-orbit terms.\n",
    "The above function is replaced by a four-layer Neural Network. \n",
    "\n",
    "<!-- dom:FIGURE: [figures/energyconvergence.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/energyconvergence.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ae23b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conclusions and where do we stand\n",
    "* Lots of experimental analysis coming, see for example [Unsupervised Learning for Identifying Events in Active Target Experiments by Solli et al.](https://arxiv.org/abs/2008.02757) as well references and examples in  [Report from the A.I. For Nuclear Physics  Workshop by Bedaque et al.](https://arxiv.org/abs/2006.05422).\n",
    "\n",
    "* Extension of the work of [G. Carleo and M. Troyer, Science **355**, Issue 6325, pp. 602-606 (2017)](http://science.sciencemag.org/content/355/6325/602) gives excellent results for two-electron systems as well as good agreement with standard VMC calculations for many  electrons.\n",
    "\n",
    "* Promising results with neural Networks as well. Next step is to use trial wave function in final Green's function Monte Carlo calculations. \n",
    "\n",
    "* Minimization problem can be tricky.\n",
    "\n",
    "* Anti-symmetry dealt with multiplying the trail wave function with either a simple or an optimized Slater determinant.\n",
    "\n",
    "* Extend to more fermions. How do we deal with the antisymmetry of the multi-fermion wave function?\n",
    "\n",
    "a. Here we also used standard Hartree-Fock theory to define an optimal Slater determinant. Takes care of the antisymmetry. What about constructing an anti-symmetrized network function?\n",
    "\n",
    "b. Use thereafter ML to determine the correlated part of the wafe function (including a standard Jastrow factor).\n",
    "\n",
    "* Can we use ML to find out which correlations are relevant and thereby diminish the dimensionality problem in standard many-body  theories? \n",
    "\n",
    "* And many more exciting research avenues\n",
    "\n",
    "Need for Machine Learning and Uncertainty Quantification in nuclear physics theory.\n",
    "Good progress but much remains to be done.\n",
    "\n",
    "To solve many complex problems in the field and facilitate discoveries, multidisciplinary efforts efforts are required involving scientists in  nuclear physics, statistics, computational science, and applied math. \n",
    "The community needs to invest in relevant educational efforts."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
