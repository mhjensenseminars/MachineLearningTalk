{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Machine Learning applied to solving Nuclear Many-body Problems -->\n",
    "# Machine Learning applied to solving Nuclear Many-body Problems\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen at Department of Physics and Astronomy and FRIB/NSCL Laboratory, Michigan State University, USA & Department of Physics and Center for Computing in Science Education, University of Oslo, Norway -->\n",
    "<!-- Author: -->  \n",
    "**Morten Hjorth-Jensen**, Department of Physics and Astronomy and FRIB/NSCL Laboratory, Michigan State University, USA and Department of Physics and Center for Computing in Science Education, University of Oslo, Norway\n",
    "\n",
    "Date: **IAEA AI Technical Meeting: Nuclear Physics Working Group, October 25-29, 2021**\n",
    "\n",
    "## What is this talk about?\n",
    "The main aim is to give you a short introduction to  how we can use Machine Learning methods\n",
    "to solve quantum mechanical many-body problems. And why this could be of interest.\n",
    "\n",
    "\n",
    "Thanks to Jane Kim (MSU), Julie Butler (MSU), Vilde Flugsrud (UiO), Even Nordhagen (UiO), Alessandro Lovato (ANL).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## More material\n",
    "More in depth notebooks and lecture notes are at \n",
    "1. Making a professional Monte Carlo code for quantum mechanical simulations <http://compphysics.github.io/ComputationalPhysics2/doc/LectureNotes/_build/html/vmcdmc.html>\n",
    "\n",
    "2. From Variational Monte Carlo to Boltzmann Machines <http://compphysics.github.io/ComputationalPhysics2/doc/LectureNotes/_build/html/boltzmannmachines.html>\n",
    "\n",
    "3. [Nuclear Talent course on Machine Learning in Nuclear Experiment and Theory, June 22 - July 3, 2020](https://nucleartalent.github.io/MachineLearningECT/doc/web/course.html)\n",
    "\n",
    "4. [Machine Learning course](https://compphysics.github.io/MachineLearning/doc/web/course.html)\n",
    "\n",
    "Feel free to try them  out and please don't hesitate to ask if something is unclear.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Why? Basic motivation\n",
    "\n",
    "How can we avoid the dimensionality curse? Many possibilities\n",
    "1. smarter basis functions\n",
    "\n",
    "2. resummation of specific correlations\n",
    "\n",
    "3. stochastic sampling of high-lying states (stochastic FCI, CC and SRG/IMSRG)\n",
    "\n",
    "4. many more\n",
    "\n",
    "Machine Learning and Quantum Computing hold also great promise in tackling the \n",
    "ever increasing dimensionalities. A hot new field is  **Quantum Machine Learning**, see for example the recent textbook by [Maria Schuld and Francesco Petruccione](https://www.springer.com/gp/book/9783319964232). Here we will focus on Machine Learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What are the basic ingredients?\n",
    "Almost every problem in ML and data science starts with the same ingredients:\n",
    "* The dataset $\\mathbf{x}$ (could be some observable quantity of the system we are studying)\n",
    "\n",
    "* A model which is a function of a set of parameters $\\mathbf{\\alpha}$ that relates to the dataset, say a likelihood  function $p(\\mathbf{x}\\vert \\mathbf{\\alpha})$ or just a simple model $f(\\mathbf{\\alpha})$\n",
    "\n",
    "* A so-called **loss/cost/risk** function $\\mathcal{C} (\\mathbf{x}, f(\\mathbf{\\alpha}))$ which allows us to decide how well our model represents the dataset. \n",
    "\n",
    "We seek to minimize the function $\\mathcal{C} (\\mathbf{x}, f(\\mathbf{\\alpha}))$ by finding the parameter values which minimize $\\mathcal{C}$. This leads to  various minimization algorithms. It may surprise many, but at the heart of all machine learning algortihms there is an optimization problem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Quantum Monte Carlo Motivation\n",
    "**Basic steps.**\n",
    "\n",
    "Choose a trial wave function\n",
    "$\\psi_T(\\boldsymbol{R})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\boldsymbol{R},\\boldsymbol{\\alpha})= \\frac{\\left|\\psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})\\right|^2}{\\int \\left|\\psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})\\right|^2d\\boldsymbol{R}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our model, or likelihood/probability distribution function  (PDF). It depends on some variational parameters $\\boldsymbol{\\alpha}$.\n",
    "The approximation to the expectation value of the Hamiltonian is now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle E[\\boldsymbol{\\alpha}] \\rangle = \n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R},\\boldsymbol{\\alpha})H(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R},\\boldsymbol{\\alpha})\\Psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the codes\n",
    "\n",
    "You can find the codes for the simple two-electron case at <http://compphysics.github.io/ComputationalPhysics2/doc/LectureNotes/_build/html/boltzmannmachines.html>. \n",
    "\n",
    "\n",
    "The trial wave function are based on the product of a Slater determinant with either only Hermitian polynomials or Gaussian orbitals, with and without a Pade-Jastrow factor (PJ).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Energy as function of iterations, $N=2$ electrons\n",
    "<!-- dom:FIGURE: [figures/figN2.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "<img src=\"figures/figN2.png\" width=700><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p><!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Onebody densities $N=6$, $\\hbar\\omega=1.0$ a.u.\n",
    "\n",
    "<!-- dom:FIGURE: [figures/OB6hw1.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "<img src=\"figures/OB6hw1.png\" width=700><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p><!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Onebody densities $N=6$, $\\hbar\\omega=0.1$ a.u.\n",
    "\n",
    "<!-- dom:FIGURE: [figures/OB6hw01.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "<img src=\"figures/OB6hw01.png\" width=700><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p><!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Onebody densities $N=30$, $\\hbar\\omega=1.0$ a.u.\n",
    "<!-- dom:FIGURE: [figures/OB30hw1.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "<img src=\"figures/OB30hw1.png\" width=700><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p><!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Onebody densities $N=30$, $\\hbar\\omega=0.1$ a.u.\n",
    "<!-- dom:FIGURE: [figures/OB30hw01.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "<img src=\"figures/OB30hw01.png\" width=700><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p><!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "## Or using Deep Learning Neural Networks\n",
    "\n",
    "[Machine Learning and the Deuteron by Kebble and Rios](https://www.sciencedirect.com/science/article/pii/S0370269320305463?via%3Dihub) and \n",
    "[Variational Monte Carlo calculations of $A\\le 4$ nuclei with an artificial neural-network correlator ansatz by Adams et al.](https://arxiv.org/abs/2007.14282)\n",
    "[Nuclei with up to $A=6$ nucleons with artificial neural network wave functions, by Gnech et al](https://arxiv.org/abs/2108.06836)\n",
    "\n",
    "**Adams et al**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H_{LO} =-\\sum_i \\frac{{\\vec{\\nabla}_i^2}}{2m_N}\n",
    "+\\sum_{i<j} {\\left(C_1  + C_2\\, \\vec{\\sigma_i}\\cdot\\vec{\\sigma_j}\\right)\n",
    "e^{-r_{ij}^2\\Lambda^2 / 4 }}\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "+D_0 \\sum_{i<j<k} \\sum_{\\text{cyc}}\n",
    "{e^{-\\left(r_{ik}^2+r_{ij}^2\\right)\\Lambda^2/4}}\\,,\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $m_N$ is the mass of the nucleon, $\\vec{\\sigma_i}$ is the Pauli\n",
    "matrix acting on nucleon $i$, and $\\sum_{\\text{cyc}}$ stands for the\n",
    "cyclic permutation of $i$, $j$, and $k$. The low-energy constants\n",
    "$C_1$ and $C_2$ are fit to the deuteron binding energy and to the\n",
    "neutron-neutron scattering length\n",
    "\n",
    "\n",
    "## Replacing the Jastrow factor with Neural Networks\n",
    "\n",
    "An appealing feature of the ANN ansatz is that it is more general than the more conventional product of two-\n",
    "and three-body spin-independent Jastrow functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "|\\Psi_V^J \\rangle = \\prod_{i<j<k} \\Big( 1-\\sum_{\\text{cyc}} u(r_{ij}) u(r_{jk})\\Big) \\prod_{i<j} f(r_{ij}) | \\Phi\\rangle\\,,\n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is commonly used for nuclear Hamiltonians that do not contain tensor and spin-orbit terms.\n",
    "The above function is replaced by a four-layer Neural Network. \n",
    "\n",
    "<!-- dom:FIGURE: [figures/energyconvergence.png, width=700 frac=0.9] -->\n",
    "<!-- begin figure -->\n",
    "<img src=\"figures/energyconvergence.png\" width=700><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p><!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "## Conclusions and where do we stand\n",
    "* Extension of the work of [G. Carleo and M. Troyer, Science **355**, Issue 6325, pp. 602-606 (2017)](http://science.sciencemag.org/content/355/6325/602) gives excellent results for two-electron systems as well as good agreement with standard VMC calculations for many  electrons.\n",
    "\n",
    "* Promising results with neural Networks as well. Next step is to use trial wave function in final Green's function Monte Carlo calculations. \n",
    "\n",
    "* Minimization problem can be tricky.\n",
    "\n",
    "* Anti-symmetry dealt with multiplying the trail wave function with either a simple or an optimized Slater determinant.\n",
    "\n",
    "* Extend to more fermions. How do we deal with the antisymmetry of the multi-fermion wave function?\n",
    "\n",
    "a. Here we also used standard Hartree-Fock theory to define an optimal Slater determinant. Takes care of the antisymmetry. What about constructing an anti-symmetrized network function?\n",
    "\n",
    "b. Use thereafter ML to determine the correlated part of the wafe function (including a standard Jastrow factor).\n",
    "\n",
    "\n",
    "* Can we use ML to find out which correlations are relevant and thereby diminish the dimensionality problem in say CC or SRG theories? \n",
    "\n",
    "* And many more exciting research avenues"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
