<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html geilonn.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=geilonn-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Setting up a neural network code, part 2">
<title>Setting up a neural network code, part 2</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html geilonn.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=geilonn-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Content', 2, None, 'content'),
              ('Videos on Neural Networks',
               2,
               None,
               'videos-on-neural-networks'),
              ('Mathematics of deep learning',
               2,
               None,
               'mathematics-of-deep-learning'),
              ('Mathematics of deep learning and neural networks',
               2,
               None,
               'mathematics-of-deep-learning-and-neural-networks'),
              ('Basics of an NN', 2, None, 'basics-of-an-nn'),
              ('Overarching view of a neural network',
               2,
               None,
               'overarching-view-of-a-neural-network'),
              ('The optimization problem', 2, None, 'the-optimization-problem'),
              ('Parameters of neural networks',
               2,
               None,
               'parameters-of-neural-networks'),
              ('Other ingredients of a neural network',
               2,
               None,
               'other-ingredients-of-a-neural-network'),
              ('Other parameters', 2, None, 'other-parameters'),
              ('Universal approximation theorem',
               2,
               None,
               'universal-approximation-theorem'),
              ('Some parallels from real analysis',
               2,
               None,
               'some-parallels-from-real-analysis'),
              ('The approximation theorem in words',
               2,
               None,
               'the-approximation-theorem-in-words'),
              ('More on the general approximation theorem',
               2,
               None,
               'more-on-the-general-approximation-theorem'),
              ('Class of functions we can approximate',
               2,
               None,
               'class-of-functions-we-can-approximate'),
              ('Setting up the equations for a neural network',
               2,
               None,
               'setting-up-the-equations-for-a-neural-network'),
              ('Layout of a neural network with three hidden layers',
               2,
               None,
               'layout-of-a-neural-network-with-three-hidden-layers'),
              ('Definitions', 2, None, 'definitions'),
              ('Inputs to the activation function',
               2,
               None,
               'inputs-to-the-activation-function'),
              ('Derivatives and the chain rule',
               2,
               None,
               'derivatives-and-the-chain-rule'),
              ('Derivative of the cost function',
               2,
               None,
               'derivative-of-the-cost-function'),
              ('Bringing it together, first back propagation equation',
               2,
               None,
               'bringing-it-together-first-back-propagation-equation'),
              ('Analyzing the last results',
               2,
               None,
               'analyzing-the-last-results'),
              ('More considerations', 2, None, 'more-considerations'),
              ('Derivatives in terms of $z_j^L$',
               2,
               None,
               'derivatives-in-terms-of-z-j-l'),
              ('Bringing it together', 2, None, 'bringing-it-together'),
              ('Final back propagating equation',
               2,
               None,
               'final-back-propagating-equation'),
              ('Using the chain rule and summing over all $k$ entries',
               2,
               None,
               'using-the-chain-rule-and-summing-over-all-k-entries'),
              ('Setting up the back propagation algorithm',
               2,
               None,
               'setting-up-the-back-propagation-algorithm'),
              ('Setting up the back propagation algorithm, part 2',
               2,
               None,
               'setting-up-the-back-propagation-algorithm-part-2'),
              ('Setting up the Back propagation algorithm, part 3',
               2,
               None,
               'setting-up-the-back-propagation-algorithm-part-3'),
              ('Updating the gradients', 2, None, 'updating-the-gradients'),
              ('Limitations of supervised learning with deep networks',
               2,
               None,
               'limitations-of-supervised-learning-with-deep-networks'),
              ('Limitations of NNs', 2, None, 'limitations-of-nns'),
              ('Homogeneous data', 2, None, 'homogeneous-data'),
              ('More limitations', 2, None, 'more-limitations'),
              ('Using TensorFlow: Collect and pre-process data',
               2,
               None,
               'using-tensorflow-collect-and-pre-process-data'),
              ('And a similar code using PyTorch',
               2,
               None,
               'and-a-similar-code-using-pytorch')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="geilonn-bs.html">Setting up a neural network code, part 2</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._geilonn-bs001.html#content" style="font-size: 80%;">Content</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs002.html#videos-on-neural-networks" style="font-size: 80%;">Videos on Neural Networks</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs003.html#mathematics-of-deep-learning" style="font-size: 80%;">Mathematics of deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs004.html#mathematics-of-deep-learning-and-neural-networks" style="font-size: 80%;">Mathematics of deep learning and neural networks</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs005.html#basics-of-an-nn" style="font-size: 80%;">Basics of an NN</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs006.html#overarching-view-of-a-neural-network" style="font-size: 80%;">Overarching view of a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs007.html#the-optimization-problem" style="font-size: 80%;">The optimization problem</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs008.html#parameters-of-neural-networks" style="font-size: 80%;">Parameters of neural networks</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs009.html#other-ingredients-of-a-neural-network" style="font-size: 80%;">Other ingredients of a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs010.html#other-parameters" style="font-size: 80%;">Other parameters</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs011.html#universal-approximation-theorem" style="font-size: 80%;">Universal approximation theorem</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs012.html#some-parallels-from-real-analysis" style="font-size: 80%;">Some parallels from real analysis</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs013.html#the-approximation-theorem-in-words" style="font-size: 80%;">The approximation theorem in words</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs014.html#more-on-the-general-approximation-theorem" style="font-size: 80%;">More on the general approximation theorem</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs015.html#class-of-functions-we-can-approximate" style="font-size: 80%;">Class of functions we can approximate</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs016.html#setting-up-the-equations-for-a-neural-network" style="font-size: 80%;">Setting up the equations for a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs017.html#layout-of-a-neural-network-with-three-hidden-layers" style="font-size: 80%;">Layout of a neural network with three hidden layers</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs018.html#definitions" style="font-size: 80%;">Definitions</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs019.html#inputs-to-the-activation-function" style="font-size: 80%;">Inputs to the activation function</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs020.html#derivatives-and-the-chain-rule" style="font-size: 80%;">Derivatives and the chain rule</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs021.html#derivative-of-the-cost-function" style="font-size: 80%;">Derivative of the cost function</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs022.html#bringing-it-together-first-back-propagation-equation" style="font-size: 80%;">Bringing it together, first back propagation equation</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs023.html#analyzing-the-last-results" style="font-size: 80%;">Analyzing the last results</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs024.html#more-considerations" style="font-size: 80%;">More considerations</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs025.html#derivatives-in-terms-of-z-j-l" style="font-size: 80%;">Derivatives in terms of \( z_j^L \)</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs026.html#bringing-it-together" style="font-size: 80%;">Bringing it together</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs027.html#final-back-propagating-equation" style="font-size: 80%;">Final back propagating equation</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs028.html#using-the-chain-rule-and-summing-over-all-k-entries" style="font-size: 80%;">Using the chain rule and summing over all \( k \) entries</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs029.html#setting-up-the-back-propagation-algorithm" style="font-size: 80%;">Setting up the back propagation algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs030.html#setting-up-the-back-propagation-algorithm-part-2" style="font-size: 80%;">Setting up the back propagation algorithm, part 2</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs031.html#setting-up-the-back-propagation-algorithm-part-3" style="font-size: 80%;">Setting up the Back propagation algorithm, part 3</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs032.html#updating-the-gradients" style="font-size: 80%;">Updating the gradients</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs033.html#limitations-of-supervised-learning-with-deep-networks" style="font-size: 80%;">Limitations of supervised learning with deep networks</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs034.html#limitations-of-nns" style="font-size: 80%;">Limitations of NNs</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs035.html#homogeneous-data" style="font-size: 80%;">Homogeneous data</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs036.html#more-limitations" style="font-size: 80%;">More limitations</a></li>
     <!-- navigation toc: --> <li><a href="#using-tensorflow-collect-and-pre-process-data" style="font-size: 80%;">Using TensorFlow: Collect and pre-process data</a></li>
     <!-- navigation toc: --> <li><a href="._geilonn-bs038.html#and-a-similar-code-using-pytorch" style="font-size: 80%;">And a similar code using PyTorch</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0037"></a>
<!-- !split -->
<h2 id="using-tensorflow-collect-and-pre-process-data" class="anchor">Using TensorFlow: Collect and pre-process data </h2>

<p>Let us look at the MINST data set.</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># import necessary packages</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">tensorflow</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">tf</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn</span> <span style="color: #008000; font-weight: bold">import</span> datasets


<span style="color: #408080; font-style: italic"># ensure the same random numbers appear every time</span>
np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">0</span>)

<span style="color: #408080; font-style: italic"># display images in notebook</span>
<span style="color: #666666">%</span>matplotlib inline
plt<span style="color: #666666">.</span>rcParams[<span style="color: #BA2121">&#39;figure.figsize&#39;</span>] <span style="color: #666666">=</span> (<span style="color: #666666">12</span>,<span style="color: #666666">12</span>)


<span style="color: #408080; font-style: italic"># download MNIST dataset</span>
digits <span style="color: #666666">=</span> datasets<span style="color: #666666">.</span>load_digits()

<span style="color: #408080; font-style: italic"># define inputs and labels</span>
inputs <span style="color: #666666">=</span> digits<span style="color: #666666">.</span>images
labels <span style="color: #666666">=</span> digits<span style="color: #666666">.</span>target

<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;inputs = (n_inputs, pixel_width, pixel_height) = &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(inputs<span style="color: #666666">.</span>shape))
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;labels = (n_inputs) = &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(labels<span style="color: #666666">.</span>shape))


<span style="color: #408080; font-style: italic"># flatten the image</span>
<span style="color: #408080; font-style: italic"># the value -1 means dimension is inferred from the remaining dimensions: 8x8 = 64</span>
n_inputs <span style="color: #666666">=</span> <span style="color: #008000">len</span>(inputs)
inputs <span style="color: #666666">=</span> inputs<span style="color: #666666">.</span>reshape(n_inputs, <span style="color: #666666">-1</span>)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;X = (n_inputs, n_features) = &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(inputs<span style="color: #666666">.</span>shape))


<span style="color: #408080; font-style: italic"># choose some random images to display</span>
indices <span style="color: #666666">=</span> np<span style="color: #666666">.</span>arange(n_inputs)
random_indices <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>choice(indices, size<span style="color: #666666">=5</span>)

<span style="color: #008000; font-weight: bold">for</span> i, image <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(digits<span style="color: #666666">.</span>images[random_indices]):
    plt<span style="color: #666666">.</span>subplot(<span style="color: #666666">1</span>, <span style="color: #666666">5</span>, i<span style="color: #666666">+1</span>)
    plt<span style="color: #666666">.</span>axis(<span style="color: #BA2121">&#39;off&#39;</span>)
    plt<span style="color: #666666">.</span>imshow(image, cmap<span style="color: #666666">=</span>plt<span style="color: #666666">.</span>cm<span style="color: #666666">.</span>gray_r, interpolation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;nearest&#39;</span>)
    plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&quot;Label: </span><span style="color: #BB6688; font-weight: bold">%d</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">%</span> digits<span style="color: #666666">.</span>target[random_indices[i]])
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Input
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.models</span> <span style="color: #008000; font-weight: bold">import</span> Sequential      <span style="color: #408080; font-style: italic">#This allows appending layers to existing models</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Dense           <span style="color: #408080; font-style: italic">#This allows defining the characteristics of a particular layer</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> optimizers             <span style="color: #408080; font-style: italic">#This allows using whichever optimiser we want (sgd,adam,RMSprop)</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> regularizers           <span style="color: #408080; font-style: italic">#This allows using whichever regularizer we want (l1,l2,l1_l2)</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.utils</span> <span style="color: #008000; font-weight: bold">import</span> to_categorical   <span style="color: #408080; font-style: italic">#This allows using categorical cross entropy as the cost function</span>

<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> train_test_split

<span style="color: #408080; font-style: italic"># one-hot representation of labels</span>
labels <span style="color: #666666">=</span> to_categorical(labels)

<span style="color: #408080; font-style: italic"># split into train and test data</span>
train_size <span style="color: #666666">=</span> <span style="color: #666666">0.8</span>
test_size <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #666666">-</span> train_size
X_train, X_test, Y_train, Y_test <span style="color: #666666">=</span> train_test_split(inputs, labels, train_size<span style="color: #666666">=</span>train_size,
                                                    test_size<span style="color: #666666">=</span>test_size)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">epochs <span style="color: #666666">=</span> <span style="color: #666666">100</span>
batch_size <span style="color: #666666">=</span> <span style="color: #666666">100</span>
n_neurons_layer1 <span style="color: #666666">=</span> <span style="color: #666666">100</span>
n_neurons_layer2 <span style="color: #666666">=</span> <span style="color: #666666">50</span>
n_categories <span style="color: #666666">=</span> <span style="color: #666666">10</span>
eta_vals <span style="color: #666666">=</span> np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-5</span>, <span style="color: #666666">1</span>, <span style="color: #666666">7</span>)
lmbd_vals <span style="color: #666666">=</span> np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-5</span>, <span style="color: #666666">1</span>, <span style="color: #666666">7</span>)
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">create_neural_network_keras</span>(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd):
    model <span style="color: #666666">=</span> Sequential()
    model<span style="color: #666666">.</span>add(Dense(n_neurons_layer1, activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;sigmoid&#39;</span>, kernel_regularizer<span style="color: #666666">=</span>regularizers<span style="color: #666666">.</span>l2(lmbd)))
    model<span style="color: #666666">.</span>add(Dense(n_neurons_layer2, activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;sigmoid&#39;</span>, kernel_regularizer<span style="color: #666666">=</span>regularizers<span style="color: #666666">.</span>l2(lmbd)))
    model<span style="color: #666666">.</span>add(Dense(n_categories, activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;softmax&#39;</span>))
    
    sgd <span style="color: #666666">=</span> optimizers<span style="color: #666666">.</span>SGD(lr<span style="color: #666666">=</span>eta)
    model<span style="color: #666666">.</span>compile(loss<span style="color: #666666">=</span><span style="color: #BA2121">&#39;categorical_crossentropy&#39;</span>, optimizer<span style="color: #666666">=</span>sgd, metrics<span style="color: #666666">=</span>[<span style="color: #BA2121">&#39;accuracy&#39;</span>])
    
    <span style="color: #008000; font-weight: bold">return</span> model
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">DNN_keras <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(eta_vals), <span style="color: #008000">len</span>(lmbd_vals)), dtype<span style="color: #666666">=</span><span style="color: #008000">object</span>)
        
<span style="color: #008000; font-weight: bold">for</span> i, eta <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(eta_vals):
    <span style="color: #008000; font-weight: bold">for</span> j, lmbd <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(lmbd_vals):
        DNN <span style="color: #666666">=</span> create_neural_network_keras(n_neurons_layer1, n_neurons_layer2, n_categories,
                                         eta<span style="color: #666666">=</span>eta, lmbd<span style="color: #666666">=</span>lmbd)
        DNN<span style="color: #666666">.</span>fit(X_train, Y_train, epochs<span style="color: #666666">=</span>epochs, batch_size<span style="color: #666666">=</span>batch_size, verbose<span style="color: #666666">=0</span>)
        scores <span style="color: #666666">=</span> DNN<span style="color: #666666">.</span>evaluate(X_test, Y_test)
        
        DNN_keras[i][j] <span style="color: #666666">=</span> DNN
        
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Learning rate = &quot;</span>, eta)
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Lambda = &quot;</span>, lmbd)
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Test accuracy: </span><span style="color: #BB6688; font-weight: bold">%.3f</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">%</span> scores[<span style="color: #666666">1</span>])
        <span style="color: #008000">print</span>()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># optional</span>
<span style="color: #408080; font-style: italic"># visual representation of grid search</span>
<span style="color: #408080; font-style: italic"># uses seaborn heatmap, could probably do this in matplotlib</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">seaborn</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">sns</span>

sns<span style="color: #666666">.</span>set()

train_accuracy <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(eta_vals), <span style="color: #008000">len</span>(lmbd_vals)))
test_accuracy <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(eta_vals), <span style="color: #008000">len</span>(lmbd_vals)))

<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(eta_vals)):
    <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(lmbd_vals)):
        DNN <span style="color: #666666">=</span> DNN_keras[i][j]

        train_accuracy[i][j] <span style="color: #666666">=</span> DNN<span style="color: #666666">.</span>evaluate(X_train, Y_train)[<span style="color: #666666">1</span>]
        test_accuracy[i][j] <span style="color: #666666">=</span> DNN<span style="color: #666666">.</span>evaluate(X_test, Y_test)[<span style="color: #666666">1</span>]

        
fig, ax <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>subplots(figsize <span style="color: #666666">=</span> (<span style="color: #666666">10</span>, <span style="color: #666666">10</span>))
sns<span style="color: #666666">.</span>heatmap(train_accuracy, annot<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>, ax<span style="color: #666666">=</span>ax, cmap<span style="color: #666666">=</span><span style="color: #BA2121">&quot;viridis&quot;</span>)
ax<span style="color: #666666">.</span>set_title(<span style="color: #BA2121">&quot;Training Accuracy&quot;</span>)
ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&quot;$\eta$&quot;</span>)
ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">&quot;$\lambda$&quot;</span>)
plt<span style="color: #666666">.</span>show()

fig, ax <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>subplots(figsize <span style="color: #666666">=</span> (<span style="color: #666666">10</span>, <span style="color: #666666">10</span>))
sns<span style="color: #666666">.</span>heatmap(test_accuracy, annot<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>, ax<span style="color: #666666">=</span>ax, cmap<span style="color: #666666">=</span><span style="color: #BA2121">&quot;viridis&quot;</span>)
ax<span style="color: #666666">.</span>set_title(<span style="color: #BA2121">&quot;Test Accuracy&quot;</span>)
ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&quot;$\eta$&quot;</span>)
ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">&quot;$\lambda$&quot;</span>)
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._geilonn-bs036.html">&laquo;</a></li>
  <li><a href="._geilonn-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._geilonn-bs029.html">30</a></li>
  <li><a href="._geilonn-bs030.html">31</a></li>
  <li><a href="._geilonn-bs031.html">32</a></li>
  <li><a href="._geilonn-bs032.html">33</a></li>
  <li><a href="._geilonn-bs033.html">34</a></li>
  <li><a href="._geilonn-bs034.html">35</a></li>
  <li><a href="._geilonn-bs035.html">36</a></li>
  <li><a href="._geilonn-bs036.html">37</a></li>
  <li class="active"><a href="._geilonn-bs037.html">38</a></li>
  <li><a href="._geilonn-bs038.html">39</a></li>
  <li><a href="._geilonn-bs038.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

