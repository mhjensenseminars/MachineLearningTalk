TITLE: Making sense of sensing? 
AUTHOR: Morten Hjorth-Jensen {copyright, 1999-present|CC BY-NC} at Department of Physics, University of Oslo, Norway
DATE: March 2025



!split
===== Motivation and Content =====

These notes aim at linking entanglement in quantum mechanical systems with quantum sensing using simple examples.
Numerical codes are included in order to illustrate basic elements of sensing.
The examples are tailored to simple one- and two-qubit systems. The material contains
o One-qubit system with basic elements of sensing
o Linking analytically solvable case with many-qubit entanglement
o Simple two-particle (or two-qubit) system to demonstrate entanglement and its links with sensing

!split
===== More material will be added =====

In particular, we will include
* Quantum computing simulations of the above systems using the Variational Quantum Eigensolver algorithm
* Discussion of Fisher entropy and other measures
* Numerical codes for general time-dependent interactions
* Initial state preparations and final results and more

Feel free to come with suggestions for addition. You can access the material at URL:"

!split
===== Literature =====

In the discussions here we have borrowed extensively from two Review of Modern Physics
articles
o _Quantum sensing_, C.L. Degen, F. Reinhard, and P. Cappellaro, Reviews of  Modern  Physics _89_, 035002 (2017), see URL:"https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.89.035002"
o _Quantum metrology with nonclassical states of atomic ensembles_, 
L. Pezz√®, A. Smerzi, M.K. Oberthaler, R. Schmied, and P. Treutlein, Reviews of  Modern  Physics _90_, 035005 (2018), see URL:"https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.90.035005"
o See also recent work by Liu et at URL:"https://www.nature.com/articles/s41534-021-00507-x"

!split
===== One-qubit system =====

In the first part of this notebook, we will analyze our systems using plain diagonalization and simple analytical manipulations.
Thereafter we will develop codes and material for performing a quantum computing simulation of the same systems. 

!split
===== Two-qubit system, Computational basis =====
Our computational basis states

!bt
\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
!et
and finally
!bt
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]
!et


!split
===== Simple system to lllustrate entanglement  =====

This system can be thought of as composed of two subsystems
$A$ and $B$. Each subsystem has computational basis states

!bt
\[
\vert 0\rangle_{\mathrm{A,B}}=\begin{bmatrix} 1 & 0\end{bmatrix}^T \hspace{1cm} \vert 1\rangle_{\mathrm{A,B}}=\begin{bmatrix} 0 & 1\end{bmatrix}^T.
\]
!et
The subsystems could represent single particles or composite many-particle systems of a given symmetry.


!split
===== Computational basis states =====

This leads to the many-body computational basis states

!bt
\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
!et
and finally
!bt
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]
!et

!split
===== Eigenstates of non-interacting Hamiltonian =====

These computational basis states define the eigenstates of the non-interacting  Hamiltonian
!bt
\[
H_0\vert 00 \rangle = \epsilon_{00}\vert 00 \rangle,
\]
!et
!bt
\[
H_0\vert 10 \rangle = \epsilon_{10}\vert 10 \rangle,
\]
!et
!bt
\[
H_0\vert 01 \rangle = \epsilon_{01}\vert 01 \rangle,
\]
!et
and
!bt
\[
H_0\vert 11 \rangle = \epsilon_{11}\vert 11 \rangle.
\]
!et

!split
===== Interaction part =====

The interacting part of the Hamiltonian $H_{\mathrm{I}}$ is given by the tensor product of two $\sigma_x$ and $\sigma_z$  matrices, respectively, that is
!bt
\[
H_{\mathrm{I}}=H_x\sigma_x\otimes\sigma_x+H_z\sigma_z\otimes\sigma_z,
\]
!et
where $H_x$ and $H_z$ are interaction strength parameters. Our final Hamiltonian matrix is given by
!bt
\[
\bm{H}=\begin{bmatrix} \epsilon_{00}+H_z & 0 & 0 & H_x \\
                       0  & \epsilon_{10}-H_z & H_x & 0 \\
		       0 & H_x & \epsilon_{01}-H_z & 0 \\
		       H_x & 0 & 0 & \epsilon_{11} +H_z \end{bmatrix}.
\] 
!et

!split
===== Density matrices =====

The four eigenstates of the above Hamiltonian matrix can in turn be used to
define density matrices. As an example, the density matrix of the
first eigenstate (lowest energy $E_0$) $\Psi_0$ is given by the outerproduct

!bt
\[
\rho_0=\left(\alpha_{00}\vert 00 \rangle+\alpha_{10}\vert 10 \rangle+\alpha_{01}\vert 01 \rangle+\alpha_{11}\vert 11 \rangle\right)\left(\alpha_{00}^*\langle 00\vert+\alpha_{10}^*\langle 10\vert+\alpha_{01}^*\langle 01\vert+\alpha_{11}^*\langle 11\vert\right),
\]
!et

where the coefficients $\alpha_{ij}$ are the eigenvector coefficients
resulting from the solution of the above eigenvalue problem. 

!split
===== Subsystems =====

We can
then in turn define the density matrix for the subsets $A$ or $B$ as

!bt
\[
\rho_A=\mathrm{Tr}_B(\rho_{0})=\langle 0 \vert \rho_{0} \vert 0\rangle_{B}+\langle 1 \vert \rho_{0} \vert 1\rangle_{B},
\]
!et

or

!bt
\[
\rho_B=\mathrm{Tr}_A(\rho_0)=\langle 0 \vert \rho_{0} \vert 0\rangle_{A}+\langle 1 \vert \rho_{0} \vert 1\rangle_{A}.
\]
!et

!split
===== Entropies =====

The density matrices for these subsets can be used to compute the
so-called von Neumann entropy, which is one of the possible measures
of entanglement. A pure state has entropy equal zero while entangled
state have an entropy larger than zero. The von-Neumann entropy is
defined as

!bt
\[
S(A,B)=-\mathrm{Tr}\left(\rho_{A,B}\log_2 (\rho_{A,B})\right).
\]
!et

!split
===== Understanding the example =====
The example here shows the above von Neumann entropy based on the
density matrix for the lowest many-body state. We see clearly a jump
in the entropy around the point where we have a level crossing. At
interaction strenght $\lambda=0$ we have many-body states purely
defined by their computational basis states. As we switch on the
interaction strength, we obtain an increased degree of mixing and the
entropy increases till we reach the level crossing point where we see
an additional and sudden increase in entropy. Similar behaviors are
observed for the other states. The most important result from this
example is that entanglement is driven by the Hamiltonian itself and
the strength of the interaction matrix elements and the
non-interacting energies.


!split
===== Code, best seen in jupyter-notebook =====
!bc pycod
%matplotlib inline
from  matplotlib import pyplot as plt
import numpy as np
from scipy.linalg import logm, expm
def log2M(a): # base 2 matrix logarithm
    return logm(a)/np.log(2.0)

dim = 4
Hamiltonian = np.zeros((dim,dim))
#number of lambda values
n = 40
lmbd = np.linspace(0.0,1.0,n)
Hx = 2.0
Hz = 3.0
# Non-diagonal part as sigma_x tensor product with sigma_x
sx = np.matrix([[0,1],[1,0]])
sx2 = Hx*np.kron(sx, sx)
# Diagonal part as sigma_z tensor product with sigma_z
sz = np.matrix([[1,0],[0,-1]])
sz2 = Hz*np.kron(sz, sz)
noninteracting = [0.0, 2.5, 6.5, 7.0]
D = np.diag(noninteracting)
Eigenvalue = np.zeros((dim,n))
Entropy = np.zeros(n)

for i in range(n): 
    Hamiltonian = lmbd[i]*(sx2+sz2)+D
    # diagonalize and obtain eigenvalues, not necessarily sorted
    EigValues, EigVectors = np.linalg.eig(Hamiltonian)
    # sort eigenvectors and eigenvalues
    permute = EigValues.argsort()
    EigValues = EigValues[permute]
    EigVectors = EigVectors[:,permute]
    # Compute density matrix for selected system state, here ground state
    DensityMatrix = np.zeros((dim,dim))
    DensityMatrix = np.outer(EigVectors[:,0],EigVectors[:,0])
    # Project down on substates and find density matrix for subsystem
    d = np.matrix([[1,0],[0,1]])
    v1 = [1.0,0.0]
    proj1 = np.kron(v1,d)
    x1 = proj1 @ DensityMatrix @ proj1.T
    v2 = [0.0,1.0]
    proj2 = np.kron(v2,d)
    x2 = proj2 @ DensityMatrix @ proj2.T
    # Total density matrix for subsystem
    total = x1+x2
    # von Neumann Entropy for subsystem 
    Entropy[i] = -np.matrix.trace(total @ log2M(total))
    # Plotting eigenvalues and entropy as functions of interaction strengths
    Eigenvalue[0,i] = EigValues[0]
    Eigenvalue[1,i] = EigValues[1]
    Eigenvalue[2,i] = EigValues[2]
    Eigenvalue[3,i] = EigValues[3]
plt.plot(lmbd, Eigenvalue[0,:] ,'b-',lmbd, Eigenvalue[1,:],'g-',)
plt.plot(lmbd, Eigenvalue[2,:] ,'r-',lmbd, Eigenvalue[3,:],'y-',)
plt.xlabel('$\lambda$')
plt.ylabel('Eigenvalues')
plt.show()
plt.plot(lmbd, Entropy)
plt.xlabel('$\lambda$')
plt.ylabel('Entropy')          
plt.show
!ec


!split
===== Hamiltonian example, simple one-qubit system  =====
See whiteboard notes

!split
===== Initialization =====

To initialize a given system to a known quantum state, we first start
with a known ground state $|0\rangle$. Then, depending on the type of
information that we want to learn about the stimulus, the measurement
scheme to be used, and the physical implementation of the quantum
system, we choose some unitary operator $U_{\text {Init }}$ such that
it transforms our state $|0\rangle$ to a desired initial superposition
state $\left|\psi_{\text {Init }}\right\rangle=a|0\rangle+b|1\rangle$
for some $a, b \in \mathbb{C}$ such that $|a|^{2}+|b|^{2}=1$.

!split
===== Effects of Stimulus =====

After the sensing state is initialized, it is exposed to the environment and evolves according to the time-evolution operator of the sensing Hamiltonian $\hat{U}_{H}$ as
!bt
\[
|\psi(t)\rangle=\hat{U}_{H}(0, t)\left|\psi_{\text {Init }}(0)\right\rangle
\]
!et
In general, $\hat{U}_{H}(0, t)=e^{\frac{i}{\hbar} \int_{0}^{t} \hat{H} d \tau}$ could be a complicated, non-analytical function for a time-dependent $V(t)$ (making $\hat{H}$ time-dependent as well).


!split
===== Slowly changing potential =====

However, in the case where $V(t)$ is constant or changes much more slowly than our sensing integration time, we can assume
!bt
\[
|\psi(t)\rangle=\hat{U}_{H}(0, t)\left|\psi_{\text {Init }}(0)\right\rangle=e^{\frac{i t}{\hbar} \hat{H}}\left|\psi_{\text {Init }}(0)\right\rangle
\]
!et
which means the sensing state evolves as
!bt
\[
|\psi(t)\rangle=\left(e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}\left|\lambda_{0}\right\rangle\left\langle\lambda_{0}\right|+e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}\left|\lambda_{1}\right\rangle\left\langle\lambda_{1}\right|\right)\left|\psi_{\text {Init }}(0)\right\rangle
\]
!et
using the spectral decomposition and the final representation of the
sensing Hamiltonian found previously (whiteboard notes).

!split
===== Readout =====

After the sensing state has time-evolved in the presence of $V(t)$, it
can be transformed again before a measurement is taken. The first
part, the transformation to some desired read-out state, is performed
by an operator $\hat{U}_{\text {Readout }}$ (which is often
$\hat{U}_{\text {Init }}^{-1}$, see Degen et al., 2017) where
!bt
\[
\left|\psi_{\text {Final }}\right\rangle=\hat{U}_{\text {Readout }}|\psi(t)\rangle
\]
!et

!split
===== Measurement =====

A measurement of this final state $\left|\psi_{\text {Final
}}\right\rangle=a^{\prime}|0\rangle+b^{\prime}|1\rangle$ is made with
respect to the basis $\{|0\rangle,|1\rangle\}$ where
$|0\rangle$ is measured with proability
!bt
\[
\left|\left\langle 0 \mid \psi_{\text {Final}}\right\rangle\right|^{2}=\left|a^{\prime}\right|^{2},
\]
!et
and $|1\rangle$ is measured with probability 
!bt
\[
\left|\left\langle 1 \mid\psi_{\text {Final}}\right\rangle\right|^{2}=\left|b^{\prime}\right|^{2}.
\]
!et


After this
measurement, the sensing state has been collapsed into one of the
basis states, so no more information can be gained.

!split
===== Multiple measurements =====

However, by having
multiple quantum sensing elements time-evolving together or by
repeating the process many times before the external stimulus $V(t)$
can change, a transition probability $p_{|0\rangle
\rightarrow|1\rangle}=\left|\left\langle 1 \mid \psi_{\text {Final
}}\right\rangle\right|^{2}=\left|b^{\prime}\right|^{2}$ can be
estimated. The 'sensing' is then accomplished by taking a series of
these transition probabilities as a time-series, and then using the
results to estimate the sensed stimulus $V(t)$ [Degen et al., 2017].


!split
===== Example =====

The simplest mathematical example of quantum sensing is sensing an
external stimulus's effect on the splitting of the energy levels of an
isolated system. Suppose our stimulus is constant and 'parallel' with
our sensor, i.e. $V_z(t)=V_{0}$ and $V_x=0$, and we choose
our initialization and readout preparation operators to be the famous
Hadamard gate

!bt
\[
\hat{U}_{H a d}=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 & 1 \\
1 & -1
\end{array}\right)
\]
!et

since $\hat{U}_{\text {Had }}^{-1}=\hat{U}_{\text {Had }}$.\\


!split
===== Evolution of initial state =====

The initial state is 

!bt
\[
\left|\psi_{\text {Init }}\right\rangle=\hat{U}_{\text {Had }}|0\rangle=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 & 1 \\
1 & -1
\end{array}\right)\binom{1}{0}=\frac{1}{\sqrt{2}}\binom{1}{1}
\]
!et
This need not necessarily be the same basis into which the system was initialized, but we'll assume it is so that we only have to keep track of one basis.

!split
===== State evolution =====

The state evolves as
!bt
\begin{align*}
|\psi(t)\rangle=&\left(e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}|0\rangle\langle 0|+e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}|1\rangle\langle 1|\right)\left|\psi_{\text {Init }}(0)\right\rangle\\
&=\left(\begin{array}{cc}
e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)} & 0 \\
0 & e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}
\end{array}\right) \frac{1}{\sqrt{2}}\binom{1}{1} \\
& =\frac{1}{\sqrt{2}}\binom{e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}}{e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}}\\
&=\frac{1}{\sqrt{2}} e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}\binom{1}{e^{\frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}}
\end{align*}
!et

!split
===== Preparing for readout =====

This is then prepared for readout as

!bt
\[
\vert\psi_{\text {Final }}\rangle=\frac{1}{2} \exp{\frac{\imath t}{\hbar}(E_{0}-\frac{1}{2} \gamma V_Z)}
\begin{bmatrix} 1+\exp{\frac{\imath t}{\hbar}(E_{1}-E_{0}+\gamma V_Z)} \\ 1-\exp{(\frac{\imath t}{\hbar}(E_{1}-E_{0}+\gamma V_Z)}\end{bmatrix}.
\]
!et

!split
===== Transition probability =====

The transition probability
!bt
\begin{align*}
p_{|0\rangle \rightarrow|1\rangle}=\left|\left\langle 1 \mid \psi_{\text {Final }}\right\rangle\right|^{2}=&\left|1-e^{\frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}\right|^{2}\\
&=\frac{1}{2}\left(1-\cos \left(t \frac{\left(E_{1}-E_{0}\right)+\gamma V_Z}{\hbar}\right)\right)
\end{align*}
!et

!split
===== "Ramsey interferometry":"https://en.wikipedia.org/wiki/Ramsey_interferometry" =====

We know the difference in energy between $E_{1}$ and $E_{0}$, either
since we constructed the system or by taking measurements without the
external stimulus $V$, and we can control the time $t$ for which the
system is allowed to evolve under the external stimulus. Then we can
fix $t$ and take many measurements to estimate $p_{|0\rangle
\rightarrow|1\rangle}$, which then makes finding $t \frac{\gamma
V_Z}{\hbar}$ a simple phase-estimation problem which gives us $\gamma
V_Z$. The physical implementation of this process is known as Ramsey
Interferometry, and it can be done with arbitary initialization and
readout preparation unitary operators.

!split
===== Benefits of Entanglement =====

Up until now, we have said that we take many measurements of
$\left|\psi_{\text {Final }}\right\rangle$ to estimate $p_{|0\rangle
\rightarrow|1\rangle}$, but we have been glossing over the estimation
process. Assuming we can take $N$ measurements, either by having $N$
experimental apparatuses running in parallel or by taking $N$
different measurements of a (relatively) constant $V$ with a single
apparatus, the uncertainty in $p$, denoted as $\sigma_{p}$ (this is a
positive real number; not to be confused with the Pauli matrices),
scales as

!bt
\[
\sigma_{p} \propto \frac{1}{\sqrt{N}}
\]
!et

!split
===== Ramsey interferometry =====

If we consider Ramsey Interferometry as an example, see URL:"https://en.wikipedia.org/wiki/Ramsey_interferometry", then the
uncertainty in $\gamma V_Z$ and so in $V_Z$, denoted $\sigma_{V}$,
scales as

!bt
\[
\sigma_{V} \propto \sigma_{p} \propto \frac{1}{\sqrt{N}}
\]
!et

This relationship is known as the standard quantum limit (SQL)
[Giovannetti et al., 2011], but can also be explained with the Law of

Large Numbers from statistics, where measuring $N$ similarly
distributed, well-behaved random variables gives the sample mean as an
estimator for the population mean and the sample variance divided by
the size of the sample as an uncertainty in the estimate of the
population mean.

!split
===== More than one qubit =====

The nature of quantum systems allows for more information to be
extracted by exploiting entanglement between quantum systems. This is
the fundamental basis for the benefits of quantum computing over
classical computing, and quantum sensing has similar benefits over
classical sensing. Suppose we return to the example above, but rather
than initializing $N$ sensing qubits separately, we initialize
$\frac{N}{n}$ groups each with $n$ entangled quantum systems. Then we
have

!bt
\[
\left|\psi_{\text {Init }}\right\rangle=\frac{1}{\sqrt{2^{n}}}\left(|0\rangle^{\otimes n}+|1\rangle^{\otimes n}\right),
\]
!et
where $|0\rangle^{\otimes n}=|0\rangle \otimes \ldots \otimes|0\rangle, n$ times.


!split
===== After initialization =====

After initialization, each of the $n$ sensing qubits evolves to pick up a relative phase factor of $e^{\frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}$, which combined results in
!bt
\[
|\psi(t)\rangle=\mathcal{N}\left(|0\rangle^{\otimes n}+e^{n \frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}|1\rangle^{\otimes n}\right)
\]
!et

where $\mathcal{N}$ is just a factor to take care of normalization.

!split
===== Transition probability =====

The transition probability
!bt
\[
p_{|0\rangle \rightarrow|1\rangle}=\left|\left\langle 1 \mid \psi_{\text {Final }}\right\rangle\right|^{2}=\frac{1}{2}\left(1-\cos \left(t \frac{n\left(E_{1}-E_{0}\right)+n \gamma V_Z}{\hbar}\right)\right)
\]
!et

!split
===== Role of entanglement =====

From this, we can see that through entangling $n$ sensing qubits, the
_signal_ we are trying to sense increases from $V_Z \rightarrow n
V_Z$, and with $\frac{N}{n}$ total measurements,
!bt
\[
\sigma_{V} \propto \frac{1}{n} \sigma_{p} \propto \frac{1}{n}\left(\frac{1}{\sqrt{\frac{N}{n}}}\right)=\frac{1}{\sqrt{N n}}
\]
!et
which means the error decreased by a factor of $\sqrt{n}$. In the case where $n=N$, the uncertainty now scales as
!bt
\[
\sigma_{V} \propto \frac{1}{N}
\]
!et
which is known as the Heisenberg limit, and is the
quantum-mechanically limited, maximal amount of information one can
get from taking $n$ quantum sensing measurements [Giovannetti et al.,
2011].

!split
===== Concluding remarks =====

Quantum sensing is an emerging field with a large number of exciting
applications. In terms of physical implementation, quantum sensors are
able to naturally be more sensitive and sense on smaller scales than
many classical sensors, while also often being directly tracable to
fundamental physical constants.

Additionally, exploiting entanglement and the quantum nature of these
devices allows for fundamentally more information to be collected than
is allowed by classical measurements and the SQL. Quantum sensing
fundamentally improves upon the physical and theoretical limitations
of classical sensing, and it will be interesting to see how and what
physical realizations develop to the point of practicality in the near
future.

