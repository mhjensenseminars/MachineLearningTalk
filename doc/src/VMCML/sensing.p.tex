%%
%% Automatically generated file from DocOnce source
%% (https://github.com/doconce/doconce/)
%% doconce format latex sensing.do.txt --latex_title_layout=beamer --latex_table_format=footnotesize --no_mako
%%
% #ifdef PTEX2TEX_EXPLANATION
%%
%% The file follows the ptex2tex extended LaTeX format, see
%% ptex2tex: https://code.google.com/p/ptex2tex/
%%
%% Run
%%      ptex2tex myfile
%% or
%%      doconce ptex2tex myfile
%%
%% to turn myfile.p.tex into an ordinary LaTeX file myfile.tex.
%% (The ptex2tex program: https://code.google.com/p/ptex2tex)
%% Many preprocess options can be added to ptex2tex or doconce ptex2tex
%%
%%      ptex2tex -DMINTED myfile
%%      doconce ptex2tex myfile envir=minted
%%
%% ptex2tex will typeset code environments according to a global or local
%% .ptex2tex.cfg configure file. doconce ptex2tex will typeset code
%% according to options on the command line (just type doconce ptex2tex to
%% see examples). If doconce ptex2tex has envir=minted, it enables the
%% minted style without needing -DMINTED.
% #endif

% #define PREAMBLE

% #ifdef PREAMBLE
%-------------------- begin preamble ----------------------

\documentclass[%
oneside,                 % oneside: electronic viewing, twoside: printing
final,                   % draft: marks overfull hboxes, figures with paths
10pt]{article}

\listfiles               %  print all files needed to compile this document

\usepackage{relsize,makeidx,color,setspace,amsmath,amsfonts,amssymb}
\usepackage[table]{xcolor}
\usepackage{bm,ltablex,microtype}

\usepackage[pdftex]{graphicx}

\usepackage{ptex2tex}
% #ifdef MINTED
\usepackage{minted}
\usemintedstyle{default}
% #endif

\usepackage[T1]{fontenc}
%\usepackage[latin1]{inputenc}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}

\usepackage{lmodern}         % Latin Modern fonts derived from Computer Modern

% Hyperlinks in PDF:
\definecolor{linkcolor}{rgb}{0,0,0.4}
\usepackage{hyperref}
\hypersetup{
    breaklinks=true,
    colorlinks=true,
    linkcolor=linkcolor,
    urlcolor=linkcolor,
    citecolor=black,
    filecolor=black,
    %filecolor=blue,
    pdfmenubar=true,
    pdftoolbar=true,
    bookmarksdepth=3   % Uncomment (and tweak) for PDF bookmarks with more levels than the TOC
    }
%\hyperbaseurl{}   % hyperlinks are relative to this root

\setcounter{tocdepth}{2}  % levels in table of contents

% --- fancyhdr package for fancy headers ---
\usepackage{fancyhdr}
\fancyhf{} % sets both header and footer to nothing
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[LE,RO]{\thepage}
% Ensure copyright on titlepage (article style) and chapter pages (book style)
\fancypagestyle{plain}{
  \fancyhf{}
  \fancyfoot[C]{{\footnotesize \copyright\ 1999-2025, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license}}
%  \renewcommand{\footrulewidth}{0mm}
  \renewcommand{\headrulewidth}{0mm}
}
% Ensure copyright on titlepages with \thispagestyle{empty}
\fancypagestyle{empty}{
  \fancyhf{}
  \fancyfoot[C]{{\footnotesize \copyright\ 1999-2025, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license}}
  \renewcommand{\footrulewidth}{0mm}
  \renewcommand{\headrulewidth}{0mm}
}

\pagestyle{fancy}


% prevent orhpans and widows
\clubpenalty = 10000
\widowpenalty = 10000

% --- end of standard preamble for documents ---


% insert custom LaTeX commands...

\raggedbottom
\makeindex

%-------------------- end preamble ----------------------

\begin{document}

% matching end for #ifdef PREAMBLE
% #endif

\newcommand{\exercisesection}[1]{\subsection*{#1}}


% ------------------- main content ----------------------



% ----------------- title -------------------------

\title{Making sense of sensing? }

% ----------------- author(s) -------------------------

\author{Morten Hjorth-Jensen\inst{1}}
\institute{Department of Physics, University of Oslo, Norway\inst{1}}
% ----------------- end author(s) -------------------------

\date{March 2025
% <optional titlepage figure>
% <optional copyright>
}

% !split
\subsection{Motivation and Content}

These notes aim at linking entanglement in quantum mechanical systems
with quantum sensing using simple examples.  Numerical codes are
included in order to illustrate basic elements of sensing.  The
examples are tailored to simple one- and two-qubit systems. The
material contains
\begin{enumerate}
\item One-qubit system with basic elements of sensing

\item Linking analytically solvable case with many-qubit entanglement and sensing

\item Simple two-particle (or two-qubit) system to demonstrate entanglement and its links with sensing (to come)
\end{enumerate}

\noindent
% !split
\subsection{More material will be added}

In particular, we will include
\begin{itemize}
\item Quantum computing simulations of the above systems using the Variational Quantum Eigensolver algorithm

\item Discussion of Fisher entropy and other measures

\item Numerical codes for general time-dependent interactions

\item Initial state preparations and final results and more
\end{itemize}

\noindent
Feel free to come with suggestions for additions. You can access the material at \href{{https://github.com/mhjensenseminars/MachineLearningTalk/blob/master/doc/pub/sensing/ipynb/sensing.ipynb}}{\nolinkurl{https://github.com/mhjensenseminars/MachineLearningTalk/blob/master/doc/pub/sensing/ipynb/sensing.ipynb}}

% !split
\subsection{Literature}

In the discussions here we have borrowed extensively from two Review of Modern Physics
articles
\begin{enumerate}
\item \textbf{Quantum sensing}, C.L. Degen, F. Reinhard, and P. Cappellaro, Reviews of  Modern  Physics \textbf{89}, 035002 (2017), see \href{{https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.89.035002}}{\nolinkurl{https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.89.035002}}

\item \textbf{Quantum metrology with nonclassical states of atomic ensembles}, L. Pezz√®, A. Smerzi, M.K. Oberthaler, R. Schmied, and P. Treutlein, Reviews of  Modern  Physics \textbf{90}, 035005 (2018), see \href{{https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.90.035005}}{\nolinkurl{https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.90.035005}}

\item See also recent work by Liu et at \href{{https://www.nature.com/articles/s41534-021-00507-x}}{\nolinkurl{https://www.nature.com/articles/s41534-021-00507-x}}. We may add codes which simulate these systems as well, stay tuned.
\end{enumerate}

\noindent
% !split
\subsection{One-qubit system}

In the first part of this notebook, we will analyze our systems using
plain diagonalization and simple analytical manipulations.  Thereafter
we will develop codes and material for performing a quantum computing
simulation of the same systems (this material is not yet ready).

Our first encounter is a simple one-qubit system, described by a simple $2\times 2$ Hamiltonian.

We start with a simple $2\times 2$ Hamiltonian matrix expressed in
terms of Pauli $\bm{X}$, $\bm{Y}$  and $\bm{Z}$ matrices. But before we proceed, a simple reminder is appropriate.

% !split
\subsection{Definitions: Single qubit gates}

The Pauli matrices (and gate operations following therefrom) are defined as
\[
	\bm{X} \equiv \sigma_x = \begin{bmatrix}
		0 & 1 \\
		1 & 0
	\end{bmatrix}, \quad
	\bm{Y} \equiv \sigma_y = \begin{bmatrix}
		0 & -i \\
		i & 0
	\end{bmatrix}, \quad
	\bm{Z} \equiv \sigma_z = \begin{bmatrix}
		1 & 0 \\
		0 & -1
	\end{bmatrix}.
\]

% !split
\subsection{Pauli-$\bm{X}$ gate}

The Pauli-$\bm{X}$ gate is also known as the \textbf{NOT} gate, which flips the state of the qubit.
\begin{align*}
	\bm{X}\vert 0\rangle &= \vert 1\rangle, \\
	\bm{X}\vert 1\rangle &= \vert 0\rangle.	
\end{align*}
The Pauli-$\bm{Y}$ gate flips the bit and multiplies the phase by $ i $. 
\begin{align*}
	\bm{Y}\vert 0\rangle &= i\vert 1\rangle, \\
	\bm{Y}\vert 1\rangle &= -i\vert 0\rangle.
\end{align*}
The Pauli-$\bm{Z}$ gate multiplies only the phase of $\vert 1\rangle$ by $ -1 $.
\begin{align*}
	\bm{Z}\vert 0\rangle &= \vert 0\rangle, \\
	\bm{Z}\vert 1\rangle &= -\vert 1\rangle.
\end{align*}

% !split
\subsection{Hadamard gate}

The Hadamard gate is defined as
\[
	\bm{H} = \frac{1}{\sqrt{2}} \begin{bmatrix}
		1 & 1 \\
		1 & -1
	\end{bmatrix}.
\]

It creates a superposition of the $ \vert 0\rangle $ and $ \vert 1\rangle $ states.
\begin{align}
	\bm{H}\vert 0\rangle &= \frac{1}{\sqrt{2}} \left( \vert 0\rangle + \vert 1\rangle \right), \\
	\bm{H}\vert 1\rangle &= \frac{1}{\sqrt{2}} \left( \vert 0\rangle - \vert 1\rangle \right).
\end{align}
Note that we will use $H$ as symbol for the Hadamard gate while we will reserve the notation $\mathcal{H}$ for a given Hamiltonian.

% !split
\subsection{Sensing Hamiltonian}

For our discussions, we will assume that the quantum sensor can be
described by the generic Hamiltonian (we follow here Degen \emph{et al.,}
\[
\hat{H}(t) = \hat{H}_0 + \hat{H}_I(t) + \hat{H}_\mathrm{control}(t),
\]

where $\hat{H}_0$ is the internal Hamiltonian, $\hat{H}_I(t)$ is the
Hamiltonian associated with a signal ($V(t)$ in the notes below), and
$\hat{H}_\mathrm{control}(t)$ is the control Hamiltonian.  Following the above mentioned authors, we  will assume
that $\hat{H}_0$ is known and that $\hat{H}_\mathrm{control}(t)$ can be
deliberately chosen so as to manipulate or tune the sensor in a
controlled way.

The goal of a quantum sensing experiment is then to
infer $V(t)$ from the effect it has on the qubit via its Hamiltonian
$\hat{H}_I(t)$, usually by a clever choice of
$\hat{H}_\mr{control}(t)$.

% !split
\subsection{Time-dependent Hamiltonian matrix}

We define a  hermitian  matrix  $H\in {\mathbb{R}}^{2\times 2}$
\[
\mathcal{H} = \begin{bmatrix} \mathcal{H}_{11} & \mathcal{H}_{12} \\ \mathcal{H}_{21} & \mathcal{H}_{22}
\end{bmatrix},
\]
We  let $\mathcal{H} = \mathcal{H}_0 + \mathcal{H}_I$, where
\[
\mathcal{H}_0= \begin{bmatrix} E_0 & 0 \\ 0 & E_1\end{bmatrix},
\]
is a diagonal matrix. Similarly,
\[
\mathcal{H}_I(t)= \begin{bmatrix} V_{11}(t) & V_{12}(t) \\ V_{21}(t) & V_{22}(t)\end{bmatrix},
\]
where $V_{ij}(t)$ represent various time-dependent interaction matrix elements and since we have a hermitian matrix, we require that
$V_{21}=V_{12}^*$.

% !split
\subsection{Interaction part}

We will now label  the interaction matrix elements, assuming that they have an explicit time dependence.
We define
\begin{align*}
V_{11} & = V_z(t)\\
V_{22} & = -V_z(t)\\
V_{12} & = V_x(t)-\imath V_y(t).
\end{align*}

In the numerical example below we let $V_y(t)=0$, $V_z(t) = tV_z$
and $V_x(t) = tV_x$ with $V_z$ and $V_x$ real-valued constants to
be determined. In the same numerical example we let $t\in [0,1]$.

% !split
\subsection{Non-interacting solution}

We can view $H_0$ as the non-interacting solution
\[
       \mathcal{H}_0\vert 0 \rangle =E_0\vert 0 \rangle,
\]
and
\[
       \mathcal{H}_0\vert 1\rangle =E_1\vert 1\rangle,
\]
where we have defined the orthogonal computational one-qubit basis states $\vert 0\rangle$ and $\vert 1\rangle$.

% !split
\subsection{Rewriting with Pauli matrices}

We rewrite $H$ (and $H_0$ and $H_I$)  via Pauli matrices
\[
\mathcal{H}_0 = \mathcal{E}_{\mathrm{avg}} I -\Delta E \bm{Z}, \quad \mathcal{E}_{\mathrm{avg}} = \frac{E_0
  + E_1}{2}, \; \Delta E = \frac{E_1-E_0}{2},
\]
and
\[
\mathcal{H}_I = V_z(t)\bm{Z} + V_x(t)\bm{X}+V_y(t)\bm{Y},
\]
with $V_z(t) = V_{11}=-V_{22}$, $V_x(t) = \Re (V)_{12}$ and $V_y(t) = \Im (V)_{12}$.

% !split
\subsection{Simple time dependence}
We let our Hamiltonian depend linearly on time  $t$

\[
\mathcal{H}=\mathcal{H}_0+t \mathcal{H}_\mathrm{I},
\]

with $t \in [0,1]$, where the limits $t=0$ and $t=1$
represent the non-interacting (or unperturbed) and fully interacting
system, respectively. This means that the various potential terms are given by $V_i(t)=tV_i$, with $i=\{x,y,z\}$ and $V_i$ real-valued constants.

% !split
\subsection{Selecting parameters}

The model is an eigenvalue problem with only
two available states.

Here we set the parameters $E_1=0$,
$E_2=4$, $V_{11}=-V_{22}=3$ and $V_{12}=V_{21}=0.2$.

The non-interacting solutions represent our computational basis.
Pertinent to our choice of parameters, is that at $\lambda\geq 2/3$,
the lowest eigenstate is dominated by $\vert 1\rangle$ while the upper
is $\vert 0 \rangle$. At $\lambda=1$ the $\vert 0 \rangle$ mixing of
the lowest eigenvalue is $1\%$ while for $\lambda\leq 2/3$ we have a
$\vert 0 \rangle$ component of more than $90\%$.  The character of the
eigenvectors has therefore been interchanged when passing $z=2/3$. The
value of the parameter $V_{12}$ represents the strength of the coupling
between the two states.

% !split
\subsection{Setting up the matrix}
This part is best seen using the jupyter-notebook






















\bpycod
from  matplotlib import pyplot as plt
import numpy as np
dim = 2
Hamiltonian = np.zeros((dim,dim))
e0 = 0.0
e1 = 4.0
Xnondiag = 0.20
Xdiag = 3.0
Eigenvalue = np.zeros(dim)
# setting up the Hamiltonian
Hamiltonian[0,0] = Xdiag+e0
Hamiltonian[0,1] = Xnondiag
Hamiltonian[1,0] = Hamiltonian[0,1]
Hamiltonian[1,1] = e1-Xdiag
# diagonalize and obtain eigenvalues, not necessarily sorted
EigValues, EigVectors = np.linalg.eig(Hamiltonian)
permute = EigValues.argsort()
EigValues = EigValues[permute]
# print only the lowest eigenvalue
print(EigValues[0])

\epycod


Now rewrite it in terms of the identity matrix and the Pauli matrix X and Z

















\bpycod
# Now rewrite it in terms of the identity matrix and the Pauli matrix X and Z
X = np.array([[0,1],[1,0]])
Y = np.array([[0,-1j],[1j,0]])
Z = np.array([[1,0],[0,-1]])
# identity matrix
I = np.array([[1,0],[0,1]])

epsilon = (e0+e1)*0.5; omega = (e0-e1)*0.5
c = 0.0; omega_z=Xdiag; omega_x = Xnondiag
Hamiltonian = (epsilon+c)*I+(omega_z+omega)*Z+omega_x*X
EigValues, EigVectors = np.linalg.eig(Hamiltonian)
permute = EigValues.argsort()
EigValues = EigValues[permute]
# print only the lowest eigenvalue
print(EigValues[0])

\epycod


% !split
\subsection{Initialization}

To initialize a given system to a known quantum state, we first start
with a known ground state $|0\rangle$. Then, depending on the type of
information that we want to learn about the stimulus, the measurement
scheme to be used, and the physical implementation of the quantum
system, we choose some unitary operator $U_{\text {Init }}$ such that
it transforms our state $|0\rangle$ to a desired initial superposition
state $\left|\psi_{\text {Init }}\right\rangle=a|0\rangle+b|1\rangle$
for some $a, b \in \mathbb{C}$ such that $|a|^{2}+|b|^{2}=1$.

% !split
\subsection{Effects of Stimulus}

After the sensing state is initialized, it is exposed to the environment and evolves according to the time-evolution operator of the sensing Hamiltonian $\hat{U}_{H}$ as
\[
|\psi(t)\rangle=\hat{U}_{H}(0, t)\left|\psi_{\text {Init }}(0)\right\rangle
\]
In general, $\hat{U}_{H}(0, t)=e^{\frac{i}{\hbar} \int_{0}^{t} \hat{H} d \tau}$ could be a complicated, non-analytical function for a time-dependent $V(t)$ (making $\hat{H}$ time-dependent as well).

% !split
\subsection{Slowly changing potential}

However, in the case where $V(t)$ is constant or changes much more slowly than our sensing integration time, we can assume
\[
|\psi(t)\rangle=\hat{U}_{H}(0, t)\left|\psi_{\text {Init }}(0)\right\rangle=e^{\frac{i t}{\hbar} \hat{H}}\left|\psi_{\text {Init }}(0)\right\rangle
\]
which means the sensing state evolves as
\[
|\psi(t)\rangle=\left(e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}\left|\lambda_{0}\right\rangle\left\langle\lambda_{0}\right|+e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}\left|\lambda_{1}\right\rangle\left\langle\lambda_{1}\right|\right)\left|\psi_{\text {Init }}(0)\right\rangle
\]
using the spectral decomposition and the final representation of the
sensing Hamiltonian found previously (whiteboard notes).

% !split
\subsection{Readout}

After the sensing state has time-evolved in the presence of $V(t)$, it
can be transformed again before a measurement is taken. The first
part, the transformation to some desired read-out state, is performed
by an operator $\hat{U}_{\text {Readout }}$ (which is often
$\hat{U}_{\text {Init }}^{-1}$, see Degen et al., 2017) where
\[
\left|\psi_{\text {Final }}\right\rangle=\hat{U}_{\text {Readout }}|\psi(t)\rangle
\]

% !split
\subsection{Measurement}

A measurement of this final state $\left|\psi_{\text {Final
}}\right\rangle=a^{\prime}|0\rangle+b^{\prime}|1\rangle$ is made with
respect to the basis $\{|0\rangle,|1\rangle\}$ where
$|0\rangle$ is measured with proability
\[
\left|\left\langle 0 \mid \psi_{\text {Final}}\right\rangle\right|^{2}=\left|a^{\prime}\right|^{2},
\]
and $|1\rangle$ is measured with probability 
\[
\left|\left\langle 1 \mid\psi_{\text {Final}}\right\rangle\right|^{2}=\left|b^{\prime}\right|^{2}.
\]

After this
measurement, the sensing state has been collapsed into one of the
basis states, so no more information can be gained.

% !split
\subsection{Multiple measurements}

However, by having
multiple quantum sensing elements time-evolving together or by
repeating the process many times before the external stimulus $V(t)$
can change, a transition probability $p_{|0\rangle
\rightarrow|1\rangle}=\left|\left\langle 1 \mid \psi_{\text {Final
}}\right\rangle\right|^{2}=\left|b^{\prime}\right|^{2}$ can be
estimated. The 'sensing' is then accomplished by taking a series of
these transition probabilities as a time-series, and then using the
results to estimate the sensed stimulus $V(t)$ [Degen et al., 2017].

% !split
\subsection{Example}

The simplest mathematical example of quantum sensing is sensing an
external stimulus's effect on the splitting of the energy levels of an
isolated system. Suppose our stimulus is constant and 'parallel' with
our sensor, i.e.~$V_z(t)=V_{0}$ and $V_x=0$, and we choose
our initialization and readout preparation operators to be the famous
Hadamard gate

\[
\hat{U}_{H a d}=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 & 1 \\
1 & -1
\end{array}\right)
\]

since $\hat{U}_{\text {Had }}^{-1}=\hat{U}_{\text {Had }}$.\\

% !split
\subsection{Evolution of initial state}

The initial state is 

\[
\left|\psi_{\text {Init }}\right\rangle=\hat{U}_{\text {Had }}|0\rangle=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 & 1 \\
1 & -1
\end{array}\right)\binom{1}{0}=\frac{1}{\sqrt{2}}\binom{1}{1}
\]
This need not necessarily be the same basis into which the system was initialized, but we'll assume it is so that we only have to keep track of one basis.

% !split
\subsection{State evolution}

The state evolves as
\begin{align*}
|\psi(t)\rangle=&\left(e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}|0\rangle\langle 0|+e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}|1\rangle\langle 1|\right)\left|\psi_{\text {Init }}(0)\right\rangle\\
&=\left(\begin{array}{cc}
e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)} & 0 \\
0 & e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}
\end{array}\right) \frac{1}{\sqrt{2}}\binom{1}{1} \\
& =\frac{1}{\sqrt{2}}\binom{e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}}{e^{\frac{i t}{\hbar}\left(E_{1}+\frac{1}{2} \gamma V_Z\right)}}\\
&=\frac{1}{\sqrt{2}} e^{\frac{i t}{\hbar}\left(E_{0}-\frac{1}{2} \gamma V_Z\right)}\binom{1}{e^{\frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}}
\end{align*}

% !split
\subsection{Preparing for readout}

This is then prepared for readout as

\[
\vert\psi_{\text {Final }}\rangle=\frac{1}{2} \exp{\frac{\imath t}{\hbar}(E_{0}-\frac{1}{2} \gamma V_Z)}
\begin{bmatrix} 1+\exp{\frac{\imath t}{\hbar}(E_{1}-E_{0}+\gamma V_Z)} \\ 1-\exp{(\frac{\imath t}{\hbar}(E_{1}-E_{0}+\gamma V_Z)}\end{bmatrix}.
\]

% !split
\subsection{Transition probability}

The transition probability
\begin{align*}
p_{|0\rangle \rightarrow|1\rangle}=\left|\left\langle 1 \mid \psi_{\text {Final }}\right\rangle\right|^{2}=&\left|1-e^{\frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}\right|^{2}\\
&=\frac{1}{2}\left(1-\cos \left(t \frac{\left(E_{1}-E_{0}\right)+\gamma V_Z}{\hbar}\right)\right)
\end{align*}

% !split
\subsection{\href{{https://en.wikipedia.org/wiki/Ramsey_interferometry}}{Ramsey interferometry}}

We know the difference in energy between $E_{1}$ and $E_{0}$, either
since we constructed the system or by taking measurements without the
external stimulus $V$, and we can control the time $t$ for which the
system is allowed to evolve under the external stimulus. Then we can
fix $t$ and take many measurements to estimate $p_{|0\rangle
\rightarrow|1\rangle}$, which then makes finding $t \frac{\gamma
V_Z}{\hbar}$ a simple phase-estimation problem which gives us $\gamma
V_Z$. The physical implementation of this process is known as Ramsey
Interferometry, and it can be done with arbitary initialization and
readout preparation unitary operators.

% !split
\subsection{Benefits of Entanglement}

Up until now, we have said that we take many measurements of
$\left|\psi_{\text {Final }}\right\rangle$ to estimate $p_{|0\rangle
\rightarrow|1\rangle}$, but we have been glossing over the estimation
process. Assuming we can take $N$ measurements, either by having $N$
experimental apparatuses running in parallel or by taking $N$
different measurements of a (relatively) constant $V$ with a single
apparatus, the uncertainty in $p$, denoted as $\sigma_{p}$ (this is a
positive real number; not to be confused with the Pauli matrices),
scales as

\[
\sigma_{p} \propto \frac{1}{\sqrt{N}}
\]

% !split
\subsection{Ramsey interferometry}

If we consider Ramsey Interferometry as an example, see \href{{https://en.wikipedia.org/wiki/Ramsey_interferometry}}{\nolinkurl{https://en.wikipedia.org/wiki/Ramsey_interferometry}}, then the
uncertainty in $\gamma V_Z$ and so in $V_Z$, denoted $\sigma_{V}$,
scales as

\[
\sigma_{V} \propto \sigma_{p} \propto \frac{1}{\sqrt{N}}
\]

This relationship is known as the standard quantum limit (SQL)
[Giovannetti et al., 2011], but can also be explained with the Law of

Large Numbers from statistics, where measuring $N$ similarly
distributed, well-behaved random variables gives the sample mean as an
estimator for the population mean and the sample variance divided by
the size of the sample as an uncertainty in the estimate of the
population mean.

% !split
\subsection{More than one qubit}

The nature of quantum systems allows for more information to be
extracted by exploiting entanglement between quantum systems. This is
the fundamental basis for the benefits of quantum computing over
classical computing, and quantum sensing has similar benefits over
classical sensing. Suppose we return to the example above, but rather
than initializing $N$ sensing qubits separately, we initialize
$\frac{N}{n}$ groups each with $n$ entangled quantum systems. Then we
have

\[
\left|\psi_{\text {Init }}\right\rangle=\frac{1}{\sqrt{2^{n}}}\left(|0\rangle^{\otimes n}+|1\rangle^{\otimes n}\right),
\]
where $|0\rangle^{\otimes n}=|0\rangle \otimes \ldots \otimes|0\rangle, n$ times.

% !split
\subsection{After initialization}

After initialization, each of the $n$ sensing qubits evolves to pick up a relative phase factor of $e^{\frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}$, which combined results in
\[
|\psi(t)\rangle=\mathcal{N}\left(|0\rangle^{\otimes n}+e^{n \frac{i t}{\hbar}\left(E_{1}-E_{0}+\gamma V_Z\right)}|1\rangle^{\otimes n}\right)
\]

where $\mathcal{N}$ is just a factor to take care of normalization.

% !split
\subsection{Transition probability}

The transition probability
\[
p_{|0\rangle \rightarrow|1\rangle}=\left|\left\langle 1 \mid \psi_{\text {Final }}\right\rangle\right|^{2}=\frac{1}{2}\left(1-\cos \left(t \frac{n\left(E_{1}-E_{0}\right)+n \gamma V_Z}{\hbar}\right)\right)
\]

% !split
\subsection{Role of entanglement}

From this, we can see that through entangling $n$ sensing qubits, the
\textbf{signal} we are trying to sense increases from $V_Z \rightarrow n
V_Z$, and with $\frac{N}{n}$ total measurements,
\[
\sigma_{V} \propto \frac{1}{n} \sigma_{p} \propto \frac{1}{n}\left(\frac{1}{\sqrt{\frac{N}{n}}}\right)=\frac{1}{\sqrt{N n}}
\]
which means the error decreased by a factor of $\sqrt{n}$. In the case where $n=N$, the uncertainty now scales as
\[
\sigma_{V} \propto \frac{1}{N}
\]
which is known as the Heisenberg limit, and is the
quantum-mechanically limited, maximal amount of information one can
get from taking $n$ quantum sensing measurements [Giovannetti et al.,
2011].

% !split
\subsection{Concluding remarks for the simple example}

Quantum sensing is an emerging field with a large number of exciting
applications. In terms of physical implementation, quantum sensors are
able to naturally be more sensitive and sense on smaller scales than
many classical sensors, while also often being directly tracable to
fundamental physical constants.

Additionally, exploiting entanglement and the quantum nature of these
devices allows for fundamentally more information to be collected than
is allowed by classical measurements and the SQL. Quantum sensing
fundamentally improves upon the physical and theoretical limitations
of classical sensing, and it will be interesting to see how and what
physical realizations develop to the point of practicality in the near
future.

% !split
\subsection{Two-qubit system, Computational basis}

Our computational basis states

\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
and
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
and
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
and finally
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]

% !split
\subsection{Simple system to lllustrate entanglement}

This system can be thought of as composed of two subsystems
$A$ and $B$. Each subsystem has computational basis states

\[
\vert 0\rangle_{\mathrm{A,B}}=\begin{bmatrix} 1 & 0\end{bmatrix}^T \hspace{1cm} \vert 1\rangle_{\mathrm{A,B}}=\begin{bmatrix} 0 & 1\end{bmatrix}^T.
\]
The subsystems could represent single particles or composite many-particle systems of a given symmetry.

% !split
\subsection{Computational basis states}

This leads to the many-body computational basis states

\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
and
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
and
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
and finally
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]

% !split
\subsection{Eigenstates of non-interacting Hamiltonian}

These computational basis states define the eigenstates of the non-interacting  Hamiltonian
\[
H_0\vert 00 \rangle = \epsilon_{00}\vert 00 \rangle,
\]
\[
H_0\vert 10 \rangle = \epsilon_{10}\vert 10 \rangle,
\]
\[
H_0\vert 01 \rangle = \epsilon_{01}\vert 01 \rangle,
\]
and
\[
H_0\vert 11 \rangle = \epsilon_{11}\vert 11 \rangle.
\]

% !split
\subsection{Interaction part}

The interacting part of the Hamiltonian $H_{\mathrm{I}}$ is given by the tensor product of two $\sigma_x$ and $\sigma_z$  matrices, respectively, that is
\[
H_{\mathrm{I}}=H_x\sigma_x\otimes\sigma_x+H_z\sigma_z\otimes\sigma_z,
\]
where $H_x$ and $H_z$ are interaction strength parameters. Our final Hamiltonian matrix is given by
\[
\bm{H}=\begin{bmatrix} \epsilon_{00}+H_z & 0 & 0 & H_x \\
                       0  & \epsilon_{10}-H_z & H_x & 0 \\
		       0 & H_x & \epsilon_{01}-H_z & 0 \\
		       H_x & 0 & 0 & \epsilon_{11} +H_z \end{bmatrix}.
\] 

% !split
\subsection{Density matrices}

The four eigenstates of the above Hamiltonian matrix can in turn be used to
define density matrices. As an example, the density matrix of the
first eigenstate (lowest energy $E_0$) $\Psi_0$ is given by the outerproduct

\[
\rho_0=\left(\alpha_{00}\vert 00 \rangle+\alpha_{10}\vert 10 \rangle+\alpha_{01}\vert 01 \rangle+\alpha_{11}\vert 11 \rangle\right)\left(\alpha_{00}^*\langle 00\vert+\alpha_{10}^*\langle 10\vert+\alpha_{01}^*\langle 01\vert+\alpha_{11}^*\langle 11\vert\right),
\]

where the coefficients $\alpha_{ij}$ are the eigenvector coefficients
resulting from the solution of the above eigenvalue problem. 

% !split
\subsection{Subsystems}

We can
then in turn define the density matrix for the subsets $A$ or $B$ as

\[
\rho_A=\mathrm{Tr}_B(\rho_{0})=\langle 0 \vert \rho_{0} \vert 0\rangle_{B}+\langle 1 \vert \rho_{0} \vert 1\rangle_{B},
\]

or

\[
\rho_B=\mathrm{Tr}_A(\rho_0)=\langle 0 \vert \rho_{0} \vert 0\rangle_{A}+\langle 1 \vert \rho_{0} \vert 1\rangle_{A}.
\]

% !split
\subsection{Entropies}

The density matrices for these subsets can be used to compute the
so-called von Neumann entropy, which is one of the possible measures
of entanglement. A pure state has entropy equal zero while entangled
state have an entropy larger than zero. The von-Neumann entropy is
defined as

\[
S(A,B)=-\mathrm{Tr}\left(\rho_{A,B}\log_2 (\rho_{A,B})\right).
\]

% !split
\subsection{Understanding the example}
The example here shows the above von Neumann entropy based on the
density matrix for the lowest many-body state. We see clearly a jump
in the entropy around the point where we have a level crossing. At
interaction strenght $\lambda=0$ we have many-body states purely
defined by their computational basis states. As we switch on the
interaction strength, we obtain an increased degree of mixing and the
entropy increases till we reach the level crossing point where we see
an additional and sudden increase in entropy. Similar behaviors are
observed for the other states. The most important result from this
example is that entanglement is driven by the Hamiltonian itself and
the strength of the interaction matrix elements and the
non-interacting energies.

% !split
\subsection{Code, best seen in jupyter-notebook}































































\bpycod
%matplotlib inline
from  matplotlib import pyplot as plt
import numpy as np
from scipy.linalg import logm, expm
def log2M(a): # base 2 matrix logarithm
    return logm(a)/np.log(2.0)

dim = 4
Hamiltonian = np.zeros((dim,dim))
#number of lambda values
n = 40
lmbd = np.linspace(0.0,1.0,n)
Hx = 2.0
Hz = 3.0
# Non-diagonal part as sigma_x tensor product with sigma_x
sx = np.matrix([[0,1],[1,0]])
sx2 = Hx*np.kron(sx, sx)
# Diagonal part as sigma_z tensor product with sigma_z
sz = np.matrix([[1,0],[0,-1]])
sz2 = Hz*np.kron(sz, sz)
noninteracting = [0.0, 2.5, 6.5, 7.0]
D = np.diag(noninteracting)
Eigenvalue = np.zeros((dim,n))
Entropy = np.zeros(n)

for i in range(n): 
    Hamiltonian = lmbd[i]*(sx2+sz2)+D
    # diagonalize and obtain eigenvalues, not necessarily sorted
    EigValues, EigVectors = np.linalg.eig(Hamiltonian)
    # sort eigenvectors and eigenvalues
    permute = EigValues.argsort()
    EigValues = EigValues[permute]
    EigVectors = EigVectors[:,permute]
    # Compute density matrix for selected system state, here ground state
    DensityMatrix = np.zeros((dim,dim))
    DensityMatrix = np.outer(EigVectors[:,0],EigVectors[:,0])
    # Project down on substates and find density matrix for subsystem
    d = np.matrix([[1,0],[0,1]])
    v1 = [1.0,0.0]
    proj1 = np.kron(v1,d)
    x1 = proj1 @ DensityMatrix @ proj1.T
    v2 = [0.0,1.0]
    proj2 = np.kron(v2,d)
    x2 = proj2 @ DensityMatrix @ proj2.T
    # Total density matrix for subsystem
    total = x1+x2
    # von Neumann Entropy for subsystem 
    Entropy[i] = -np.matrix.trace(total @ log2M(total))
    # Plotting eigenvalues and entropy as functions of interaction strengths
    Eigenvalue[0,i] = EigValues[0]
    Eigenvalue[1,i] = EigValues[1]
    Eigenvalue[2,i] = EigValues[2]
    Eigenvalue[3,i] = EigValues[3]
plt.plot(lmbd, Eigenvalue[0,:] ,'b-',lmbd, Eigenvalue[1,:],'g-',)
plt.plot(lmbd, Eigenvalue[2,:] ,'r-',lmbd, Eigenvalue[3,:],'y-',)
plt.xlabel('$\lambda$')
plt.ylabel('Eigenvalues')
plt.show()
plt.plot(lmbd, Entropy)
plt.xlabel('$\lambda$')
plt.ylabel('Entropy')          
plt.show

\epycod



% ------------------- end of main content ---------------

% #ifdef PREAMBLE
\end{document}
% #endif

